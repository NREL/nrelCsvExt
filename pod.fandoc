Overview [#overview]
********************

The NREL CSV extension provides convenience functions for the import and export
of CSV data. The extension is *not* designed to import and export
[Haystack-compliant]`https://project-haystack.org/doc/docHaystack/Csv` CSV data,
but rather to provide a flexible interface for interacting with arbitrary,
general purpose CSV data.

The NREL CSV extension requires SkySpark 3.1 or later and
[nrelUtilityExt]`https://stackhub.org/package/nrelUtilityExt` 1.1 or later.

Importing Records [#importRecs]
*******************************

`csvImportRecs` and related functions provide flexible import and parsing of
records from CSV data.

Column Specification [#importSpec]
==================================

`csvImportRecs` accepts a column specification dictionary, or **spec**, that
governs the interpretation of CSV data columns. In the **spec**, key names match
to column names in the CSV file (after applying `toTagName`) and key values are
strings specifying a column data type. The supported data types are:

- 'axon': parsed and evaluated as literal Axon code; **use with caution!**
- 'bool': parsed as a Boolean
- 'coord': parsed as a coord
- 'date': parsed as a date
- 'datetime': parsed as a dateTime
- 'ignore': ignored (skipped)
- 'integer': parsed as an integer
- 'marker': any non-empty value is interpreted as setting a marker flag
- 'number': parsed as a number
- 'ref': parsed as a reference
- 'string': parsed as a string
- 'time': parsed as a time
- 'tags': parsed as set of tags provided as name-value pairs; must follow valid
  [Zinc]`docHaystack::Zinc` syntax
- 'uri': parsed as a uri

Any other value in **spec** will cause an error when the corresponding column is
parsed. Any column without an entry in **spec** is parsed as a string.

XStr and the Haystack collection data types (Dicts, Lists, and Grids) are not
supported directly, but can be created indirectly via Axon code using the
'"axon"' data type. However, the '"axon"' data type is not allowed in [safe
mode]`ext-nrelCsv::doc#safeImport`.

Options [#importOpts]
=====================

Options for `csvImportRecs` are passed as name-value pairs within the **opts**
argument. The following options are supported:

- 'delimiter': column delimiter character; passed through to `ioStreamCsv`
- 'noHeader': passed through to `ioStreamCsv`
- 'sep': tag and value separator used to interpret '"tags"' and '"coord"'
  data types (cannot be the same as 'delimiter'; default = '" "')
- 'template': optional dict of tags to apply to all imported records
- 'checked': Boolean; if 'true' then throw an error on parsing failures; if
  'false' return 'null' for CSV data that fails to parse (default = 'true')
- 'commit': Boolean; if 'true' commit records to the Folio as well as returning
  them (default = 'false')
- 'log': Boolean; if 'true' create a log entry for each committed record
  (default = 'false')
- 'safe': Boolean; if 'true' disallow the 'axon' column type (default = 'true';
  see [safe mode]`ext-nrelCsv::doc#safeImport`)
- 'noWarn': Boolean; if 'true' suppress warnings (default = 'false')
- 'datePattern': pattern for parsing dates (for default, see `parseDate`)
- 'dateTimePattern': pattern for parsing dateTimes (for default, see
  `parseDateTime`)
- 'timePattern': pattern for parsing times (for default, see `parseTime`)

The 'checked', 'commit', 'log', 'safe', and 'noWarn' options may be also be
passed as markers, with 'x' equivalent to 'x:true' and '-x' equivalent to
'x:false'. For date, time, and dateTime parsing patterns see
`sys::Time.toLocale`.

Safe Mode [#safeImport]
-----------------------

The '"axon"' data type uses `eval` to evaluate arbitrary Axon code and assign
the output to the imported column value. While this allows extremely flexible
and powerful imports, it also presents a security risk: `eval` will execute the
imported code with the same level of privelege as the user who called the import
function, potentially exposing the SkySpark project to malicious code.

The 'safe' option (enabled by default) disallows the '"axon"' column type;
'"axon"' columns are instead imported as strings (with a warning). Safe mode
should be disabled only if you have full control of the CSV data being imported
or otherwise have full confidence that all Axon code that will be evaluated is
safe.

Entity-Specific Import [#entityImport]
======================================

You may import [Haystack]`https://project-haystack.org/doc/docHaystack/Ontology`
'site', 'space', 'equip', 'point', and 'weatherStation' entities using the
tailored functions:

- Sites: `csvImportSites`
- Spaces: `csvImportSpaces`
- Equips: `csvImportEquips`
- Points: `csvImportPoints`
- Weather Stations: `csvImportWeatherStations`

These functions use the same [column specification]`ext-nrelCsv::doc#importSpec`
format, data types, and [options]`ext-nrelCsv::doc#importOpts` as
`csvImportRecs`. However, they provide two additional features:

- The ability to map some standard relationships ('siteRef', 'equipRef', etc.)
- An entity-specific default column specification

Mapping Refs [#importRefs]
--------------------------

Relationships for records are assigned using the following (in priority order):

1. As provided in the 'template' option
2. By parsing an appropriate column named '*Ref' of data type 'ref', if present
3. By parsing an appropriate column named '*Name' of data type 'string' and
   using the value to map the record to an existing entity by name

If multiple sources exist, the higher-priority source is used with a warning
(suppressable with the 'noWarn' option).

Mapping refs by name requires matching each imported record to an existing
target entity either by description (as returned by `dis()`; default) or by the
value of a user-specified tag on the target entity (e.g. 'navName'). To override
the default behavior, use the option:

- 'matchRefsBy': Str; tag name to use when matching and assigning refs by name

As an example, consider assigning an 'equipRef' tag to a set of imported points
based on CSV data:

- If an 'equipRef' column is available, parse it as a ref
- Else if the user specifies the option 'matchRefsBy:"navName"' and an
  'equipName' column is available, use its value to match an 'equip' record by
  the value of its 'navName' tag
- Else if an 'equipName' column is available, use its value to match an 'equip'
  record by its description, per `dis()`

The 'matchRefsBy' option applies to any name-based record matching. Different
behavior for different types of refs (e.g. sites vs. spaces) is not supported.
Instead, use post-processing or the 'template' option to assign the correct
refs.

Site Column Specification [#siteColSpec]
----------------------------------------

Default column specification for `csvImportSites`:

  Tag                | Type    | Description
  ------------------ | ------- | ------------------------------------------------------------------------------------
  siteName           | string  | Name of site; converted to 'dis' tag
  siteTags           | tags    | Arbitrary set of tags to apply
  area               | number  | Area of site
  geoAddr            | string  | Full address
  geoStreet          | string  | Street address
  geoCity            | string  | City
  geoCounty          | string  | Subdivision of state/province
  geoState           | string  | State or province
  geoCountry         | string  | Country code
  geoPostalCode      | string  | Postal code (ZIP code, in USA)
  geoCoord           | coord   | Latitude/longitude in decimal format
  primaryFunction    | string  | The primary function of the building
  tz                 | string  | String designation for site time zone
  weatherStationName | string  | Weather station name; used to construct 'weatherStationRef' via named-based matching 
  weatherStationRef  | ref     | Weather station ref; overrides 'weatherStationName'
  yearBuilt          | number  | Year in which the building was constructed

Imported sites always receive the 'site' tag, plus any user-specified template.
If 'tz' is not provided, imported sites also receive the time zone of their
associated weather station (if available) or the default project time zone.

Space Column Specification [#spaceColSpec]
------------------------------------------

Default column specification for `csvImportSpaces`:

  Tag          | Type    | Description
  ------------ | ------- | --------------------------------------------------------------------------
  spaceName    | string  | Name of space; converted to 'navName' tag
  spaceTags    | tags    | Arbitrary set of tags to apply
  floor        | marker  | Sets the 'floor' marker
  floorNum     | integer | Floor number per European convention
  ground       | marker  | Sets the 'ground' marker
  roof         | marker  | Sets the 'roof' marker
  siteName     | string  | Associated site name; used to construct 'siteRef' via named-based matching
  siteRef      | ref     | Site ref; overrides 'siteName'
  subterranean | marker  | Sets the 'subterranean' marker

Imported spaces always receive the 'space' tag, plus any user-specified
template. In addition, any imported space records that lack a 'dis' or
'disMacro' tag receive the default 'disMacro:"$siteRef $navName"'. (A custom
'disMacro' may be specified using the 'template' option.)

Equip Column Specification [#equipColSpec]
------------------------------------------

Default column specification for `csvImportEquips`:

  Tag          | Type    | Description
  ------------ | ------- | ----------------------------------------------------------------------------
  equipName    | string  | Name of equipment; converted to 'navName' tag
  equipTags    | tags    | Arbitrary set of tags to apply
  siteName     | string  | Associated site name; used to construct 'siteRef' via named-based matching
  siteRef      | ref     | Site ref; overrides 'siteName'
  spaceName    | string  | Associated space name; used to construct 'spaceRef' via named-based matching
  spaceRef     | ref     | Space ref; overrides 'spaceName'

Imported equipment always receive the 'equip' tag, plus any user-specified
template. In addition, any imported equip records that lack a 'dis' or
'disMacro' tag receive the default 'disMacro:"$siteRef $navName"'. (A custom
'disMacro' may be specified using the 'template' option.)

Point Column Specification [#pointColSpec]
------------------------------------------

Default column specification for `csvImportPoints`:

  Tag                | Type    | Description
  ------------------ | ------- | ------------------------------------------------------------------------------------
  pointName          | string  | Name of point; converted to 'navName' tag
  pointTags          | tags    | Arbitrary set of tags to apply
  equipName          | string  | Associated equip name; used to construct 'equipRef' via named-based matching
  equipRef           | ref     | Equip ref; overrides 'equipName'
  kind               | string  | Kind of point (e.g. "Number" or "Bool"); must match SkySpark kind
  siteName           | string  | Associated site name; used to construct 'siteRef' via named-based matching
  siteRef            | ref     | Site ref; overrides 'siteName'
  spaceName          | string  | Associated space name; used to construct 'spaceRef' via named-based matching
  spaceRef           | ref     | Space ref; overrides 'spaceName'
  tz                 | string  | String designation for point time zone
  unit               | string  | Unit for numeric point (e.g. "kW")
  weatherStationName | string  | Weather station name; used to construct 'weatherStationRef' via named-based matching 
  weatherStationRef  | ref     | Weather station ref; overrides 'weatherStationName'

Imported points always receive the 'point' tag, plus any user-specified
template. In addition, any imported point records that lack a 'dis' or
'disMacro' tag receive a default of:

- Regular points: 'disMacro:"$equipRef $navName"'
- Weather points: 'disMacro:"$weatherStationRef $navName"'

(A custom 'disMacro' may be specified using the 'template' option.)

If 'tz' is not provided, imported points are also assigned a time zone based on
one of the following (in priority order):

1. The associated site
2. The associated weather station
3. The default project.

For minimum Haystack compliance, 'pointTags' should include one of 'sensor',
'cmd', or 'sp' (or these tags should be imported via other columns).

Weather Station Column Specification [#weatherStationColSpec]
-------------------------------------------------------------

Default column specification for `csvImportWeatherStations`:

  Tag                | Type    | Description
  ------------------ | ------- | ------------------------------------------------
  weatherStationName | string  | Name of weather station; converted to 'dis' tag
  weatherStationTags | tags    | Arbitrary set of tags to apply
  geoAddr            | string  | Full address
  geoStreet          | string  | Street address
  geoCity            | string  | City
  geoCounty          | string  | Subdivision of state/province
  geoState           | string  | State or province
  geoCountry         | string  | Country code
  geoPostalCode      | string  | Postal code (ZIP code, in USA)
  geoCoord           | coord   | Latitude/longitude in decimal format
  geoElevation       | number  | Elevation above sea level
  tz                 | string  | String designation for weather station time zone

Imported weather stations always receive the 'weatherStation' tag, plus any
user-specified template. If 'tz' is not provided, imported weather stations also
receive the default project time zone.

Sequencing Imports [#importSequence]
====================================

For best matching of refs, use the following import sequence:

1. Weather stations
2. Sites
3. Spaces
4. Equipment
5. Points

Importing History [#importHis]
******************************

`csvImportHistory` imports time series data from a CSV source and writes it to
point histories.

Workflow [#importHisWorkflow]
=============================

`csvImportHistory` imports CSV data from a single **handle** (String or Uri),
processes it, and writes it to one or more **points**. To receive CSV data, each
point record must:

1. Be of 'kind' "Number", "Bool", or "Str"
2. Define the 'his' tag
3. Define the 'csvColumn' tag

Import control is provided by a set of global
[options]`ext-nrelCsv::doc#importHisTs` passed via **opts** and by a set
of tags attached to the target point records:

- 'csvColumn': (Required) A string or integer specifying the CSV data column
  that contains the target point's history
  - String: Specifies CSV column by name
  - Integer: Specifies CSV column by position (1st column has position 0)
- 'csvUnit': String specifying the units of numeric CSV data
- 'csvCallback': Optional callback function to be applied to the CSV data;
  follows the same conventions as [OnWrite]`ext-his::doc#onWrite` callbacks
- 'csvConvert': Optional point value conversion as described in
  [Point Conversion]`ext-point::doc#convert` to be applied to the CSV data
- 'csvRollupInterval': Number that defines a rollup interval for the CSV data
- 'csvRollupFunc': String that defines a rollup function for the CSV data

Only the 'csvColumn' tag is required. The other tags are optional, but provide a
flexible framework for post-processing the imported CSV data prior to writing
history to the target points. The key to properly specifying these tags to
achieve a desired import workflow is understanding the order of operations that
occur during data import:

1. Raw data are read from **handle**.
2. The raw data are filtered based on the provided **points**:
   - The 'tsColumn' option specifies the timestamp column(s).
   - Each point's 'csvColumn' tag specifies the value column.
3. If the timestamp is composite (made of multiple columns), timestamps are
   consolidated into a single column (see
   [timestamp pattern]`ext-nrelCsv::doc#importHisTsPattern`).
4. Timestamps are parsed according to the 'tsPattern' option (see
   [parsing timestamps]`ext-nrelCsv::doc#importHisTs`).
5. Values are parsed according to the point's 'kind' tag (see
   [parsing values]`ext-nrelCsv::doc#importHisVals`).
   - For Boolean points, numeric CSV data are converted to Boolean.
   - For numeric points, units are assigned according to the point's 'csvUnit'
     tag (overrides any embedded units).
   - If 'csvUnit' is missing and the parsed data has no embedded units, the
     point's 'unit' tag (if any) will be used instead.
6. The data are sorted ascending by timestamp.
7. If the point has a 'csvCallback' tag, the specified callback function is
   applied to the imported data.
8. If the point has a 'csvConvert' tag, the specified point conversion is
   applied to the imported data using `pointConvert`.
9. If the point has a 'csvRollupInterval' tag, the data are rolled up to the
   specified interval via `hisRollup`:
   - The 'csvRollupFunc' tag specifies the rollup function to use.
   - If 'csvRollupFunc' is missing, then `hisRollupAuto` is used instead.
10. Numeric values are converted from their original unit to the point's
    SkySpark unit.
11. Timestamps are converted to the point's time zone.
12. Data rows with timestamps that overlap with the point's existing history
   (timestamps prior to the point's 'hisEnd' tag) are dropped.
13. The data are written to SkySpark history (which triggers the
    [OnWrite]`ext-his::doc#onWrite` action if the `hisOnWrite` tag is defined).

Options [#importHisOpts]
========================

Control options for `csvImportHistory` are passed as name-value pairs within
**opts**. The following options are supported:

- 'checked': Boolean; if 'true' then throw an error on parsing failures; if
  'false' insert 'NA' for CSV data that fails to parse (default = 'true')
- 'delimiter': column delimiter character; passed through to `ioReadCsv`
- 'noHeader': passed through to `ioReadCsv`
- 'noWarn': Boolean; if 'true' suppress warnings (default = 'false')
- 'preview': enables [preview mode]`ext-nrelCsv::doc#importHisPreview` and
  specifies the number of rows to preview for each point
- 'tsColumn': specifies the timestamp column(s) (default = '"ts"'; see
  [parsing timestamps]`ext-nrelCsv::doc#importHisTs`)
- 'tsPattern': pattern(s) for parsing CSV timestamps (see
  [parsing timestamps]`ext-nrelCsv::doc#importHisTs`)
- 'tz': time zone for CSV timestamps (default = 'now().tz')

The 'checked' and 'noWarn' options may be also be passed as markers, with 'x'
equivalent to 'x:true' and '-x' equivalent to'x:false'. If the 'preview' option
is given as a marker, it defaults to 'preview:10'.

Parsing Timestamps [#importHisTs]
=================================

The 'tsColumn', 'tsPattern', and 'tz' options for `csvImportHistory` provide
flexible configuration of timestamp parsing.

Timestamp Column [#importHisTsColumn]
-------------------------------------

'tsColumn' may be any of the following:

- String: A single timestamp column by name
- Integer: A single timestamp column by index
- List of Strings: Multiple timestamp columns by name
- List of Integers: Multiple timestamp columns by index

Timestamps spread across multiple columns (such as date in one column and time
in another column) are combined in the order specified. Column indices are
zero-based, *i.e.* the first column is index 0.

Timestamp Pattern [#importHisTsPattern]
---------------------------------------

'tsPattern' may be a single string or a list of strings, each providing a 
valid dateTime patterns per `sys::Time.toLocale`.

- If no pattern is provided, parsing falls back to the `parseDateTime` default:
    "YYYY-MM-DD'T'hh:mm:SS.FFFFFFFFFz zzzz"
- If 'tsPattern' is a list, patterns are tried in order until either one is
  successful or they have all been exhausted
- If the timestamp directly encodes timezone information, then 'tz' is silently
  ignored 
- Multiple columns: timestamp columns are concatenated in order by '" "' prior
  to parsing; 'tsPattern' must reflect the expected pattern of the concatenated
  columns

Parsing Values [#importHisVals]
===============================

Values are pased according to 'kind': Number, Bool, or Str. If necessary,
numeric data are converted to Boolean with any nonzero value representing
'true'. Supports the same keywords for true, false, null, NA, NaN, and infinity
as `parseAuto`.

NA values are returned in the following circumstances:

- NA is explicitly encoded in the CSV data
- On parsing error and 'checked' is false

Previewing Data [#importHisPreview]
===================================

The 'preview' option enables preview mode. In preview mode, `csvImportHistory`
returns a list of history grids previewing the data import and does not write
the imported history to the database. The number of rows per point is limited to
the numeric value of 'preview'.

Error Handling [#importHisErrors]
=================================

`csvImportHistory` does its best to recover from import errors: any point that
encounters an import error is skipped and execution continues to the next point.
Error logging is as follows:

- If 'checked = true': Logged as errors, with an error thrown on function exit
- If 'checked = false' and 'noWarn = false': Logged as warnings, with a clean
  function exit
- If 'checked = false' and 'noWarn = true': Not logged; clean function exit

General errors are always logged and thrown, regardless of the 'checked' and
'noWarn' options.

Exporting History [#exportHis]
******************************

Not yet supported
