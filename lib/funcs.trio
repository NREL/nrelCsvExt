name:csvAddRec
func
nodoc
src:
  (rec, log, from:"csvAddRec") => do
    // Remove null tags
    rec = rec.removeNull
  
    // Log an info message
    if (log) logInfo(from, "Importing record: " + rec.dis)
  
    // Construct a diff for database commit
    diff(null, rec, {add})
  end
---
name:csvImportEquips
doc:
  Imports equip records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. The user-provided **spec**, if any, is merged with a [default column specification]`ext-nrelCsv::doc#entityImport` for importing equips. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, noWarn:false}, opts)
    
    // Record template
    template: {equip}
    if (opts.has("template")) do
      template = opts->template.merge(template)
      opts = opts.remove("template") // For downstream use by csvImportRecs
    end
    
    // Commit option
    commitRecs: opts.has("commit") and opts["commit"] != false
    opts = opts.merge({-commit}) // For downstream use by csvImportRecs
    
    // Other true/false options
    checked: opts.has("checked") and opts["checked"] != false
    log:     opts.has("log")     and opts["log"]     != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // CSV column specification
    defaultSpec: {
      equipName: "string",
      equipTags: "tags",
      siteName:  "string",
      siteRef:   "ref",
      spaceName: "string",
      spaceRef:  "ref"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
      
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, opts)
      
    // Process records
    recs: d.map() row => do
      // Merge common template
      row = row.merge(template)
      
      // Set equip description
      row = row.set("navName", row["equipName"]).remove("equipName")
      
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro")) do
        row = row.set("disMacro", "\$siteRef \$navName")
      end
      
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("siteName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
      
      // Map space
      try do
        row = row
          .set("spaceRef", getSpaceByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("spaceName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("spaceRef").remove("spaceName") // Clean up on failure
      end
      
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImportEquips")).commit
    else do
      return recs
    end
    
  end
  
  // Potential starting point for future unit tests:
  // csvImportEquips("equipName, equipTags, siteName, spaceName\n\"Main Meter\",elec meter,\"My Site\",\"My Site 1st Floor\"",{},{})
---
name:csvImportHistory
doc:"Imports point history for specified **points** from CSV data provided by **handle** and writes imported data to the database. See the [CSV extension docs]`ext-nrelCsv::doc#importHis` for implementation details, including required tags and a list of options passed via **opts**."
func
src:
  (points, handle, opts:{}) => do
  
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Default options
    opts = merge({
      checked:  true,
      noWarn:   false,
      tsColumn: "ts",
      tz:       now().tz
    }, opts)
    
    // Valid pass-through options for ioReadCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])
    
    // True/false options
    checked: opts.has("checked") and opts["checked"] != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // Preview
    preview: opts["preview"]
    if (preview == marker()) do
      preview = 100
    else if (preview != null and not preview.isNumber) do
      throw "'preview' option must be a number."
    end
  
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Helper Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Handle argument string for error messages
    handleErrString: (val) => do
      // Uri
      if (val.isUri) return "`" + val.toStr + "`"
      
      // Anything else (presumably a CSV-formatted string)
      msg: val.toStr
      if (msg.size > 100) do
        return "\"" + msg[0..99] + "..." + "\"" 
      else do
        return "\"" + msg + "\"" 
      end
    end
    
    // Map CSV column by name (string) or index (integer)
    mapCsvColName: (n, columns) => do
      // By index
      if (n.isNumber) return getSafe(columns, n)
      
      // By name
      n = n.toTagName
      if (columns.contains(n)) n else null // Returns
    end
    
    // Parse timestamp
    parseTimestamp: (x, pattern, tz, checked) => do
      // Default pattern
      if (pattern == null) do
        try do
          ts: parseDateTime(x)
        catch (ex) do
          if (checked) throw(ex)
          return null
        end
      
      // User-specified pattern
      else if (pattern.isStr) do
        ts: parseDateTime(x, pattern, tz, checked)
        
      // Set of patterns
      else do
        // Try patterns until one successed
        ts: pattern.eachWhile() (pat) => parseDateTime(x, pat, tz, false)
        
        // If none was successful, throw an exception
        if (ts == null and checked) do
          throw "Unable to parse date/time '" + x + "' using any of the specified patterns: " + pattern.toStr
        end
      end
      
      // Output
      return ts
    end
    
    // Parse value
    parseValue: (x, kind, checked) => do
      // Trim whitespace
      x = x.trim
      
      // Encoded NA or null
      if (x=="na" or x=="Na" or x=="NA") return na()
      if (x=="null" or x=="Null" or x=="NULL") return null
      
      // Boolean
      if (kind == "Bool") do
        // True
        if (x=="true" or x=="True" or x=="TRUE" or x=="T") do
          return true
        
        // False
        else if (x=="false" or x=="False" or x=="FALSE" or x=="F") do
          return false
        
        // Number -> Bool
        else do
          val: parseNumber(x, false)
          if (val != null) return (val != 0)
        end
            
      // Number
      else if (kind == "Number") do
        // Try parsing as number
        try do
          val: parseNumber(x, true)
        catch (ex) do
          // Check keywords
          if (x=="nan"  or x=="NaN"   or x=="NAN" ) return nan()
          if (x=="+inf" or x=="+Inf"  or x=="+INF") return posInf()
          if (x=="-inf" or x=="-Inf"  or x=="-INF") return negInf()
          
          // Doesn't parse
          if (checked) throw (ex)
          return na()
        end
        
        // Return result
        return val
        
      // String
      else if (kind == "Str") do
        return x
      
      // Unsupported kind
      else do
        throw "Kind \"" + kind + "\" is not supported."
      end
      
      // Checked error
      if (checked) do
        throw "Value \"" + x + "\" did not parse as kind " + kind + "."
        
      // Unchecked error
      else do
        return na()
      end
    end
    
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Write Point History to Folio
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    writePointHis: (point, timeCol, valCol, data) => do
      // Check columns
      if (valCol == null or data.missing(valCol)) do
        throw "'csvColumn' for point @" + point.toRecId.toStr + " was not found in imported CSV data."
      end
      
      // Drop all but the two columns we need
      data = data.keepCols([timeCol, valCol])
      
      // Drop rows which have empty timestamp or data
      data = data.findAll() row => row.has(timeCol) and row.has(valCol)
      
      // Parse according to point metadata
      data = data.map() row => {
        ts: parseTimestamp(row[timeCol], opts["tsPattern"], opts["tz"], checked),
        val: parseValue(row[valCol], point["kind"], checked)
      }
      
      // Drop incorrectly parsed rows (with a warning)
      before: size(data)
      data = data.findAll row => row.has("ts") and row.has("val")
      after: size(data)
      if (not noWarn and (after < before)) do
        logWarn("csvImportHistory", "Unable to parse " + (before - after) + " rows of data for column '" + valCol + "'.")
      end
      
      // Apply units
      if (point->kind=="Number" and point.has("csvUnit")) do
        data = data.hisMap() v => v.as(point->csvUnit)
      end
  
      // Sort on timestamp
      data = data.sort("ts")
      
      // Apply callback function
      if (point.has("csvCallback")) do
        // Get callback function
        cb: eval("x:" + func(point->csvCallback)->name)
  
        // Apply transformation
        data = cb(data, point)
      end
  
      // Apply value conversion
      if (point.has("csvConvert")) do
        // Apply point conversion
        data = data.hisMap() v => pointConvert(point, point->csvConvert, v)
      end
  
      // Apply rollup function
      if (point.has("csvRollupInterval")) do
        // Rollup function
        if (point.has("csvRollupFunc")) do
          // User-specified rollup function
          data = data.hisRollup(eval("x:"+point->csvRollupFunc), point->csvRollupInterval)
        else do
          // Automatic rollup function
          data = data
            .addColMeta("val", point)
            .hisRollupAuto(point->csvRollupInterval)
        end
  
        // Drop rows for which rollup function produced null data
        data = data.findAll() row => row.has("ts") and row.has("val")
  
        // Return if empty (no new data)
        if (data.isEmpty) return null
      end
  
      // Convert to SkySpark units
      if (point->kind=="Number") do
        data = data.hisMap() v => v.to(point["unit"])
      end
  
      // Convert from input timezone to point timezone
      if (point.has("tz")) do
        data = data.map() row => row.set("ts", (row->ts).toTimeZone(point->tz))
      end
  
      // Drop any data for which the point already has history
      if (point.has("hisEnd")) data = data.findAll() row => row->ts > point->hisEnd
      
      // Return if empty (no new data)
      if (data.isEmpty) return null
      
      // Preview
      if (preview != null) do
        return getSafe(data.addColMeta("val", point), 0..(preview))
      end
      
      // Write history to point
      data.hisWrite(point)
  
      // Return processed point id
      return {id:point["id"]}
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Read CSV
    try do
      data: ioReadCsv(handle, ioOpts)
      headers: colNames(data)
    catch (ex) do
      // If error, log, and rethrow error
      logErr("csvImportHistory", "Error importing CSV from provided handle: " + handleErrString(handle), ex)
      throw (ex)
    end
    
    // Timestamp column name
    if (opts->tsColumn.isList) do
      // Composite timestamp
      tsColList: (opts->tsColumn).map(n => n.mapCsvColName(headers))
      tsCol:     tsColList.concat("_")
    else do
      // Simple timestamp
      tsCol:     opts->tsColumn.mapCsvColName(headers)
      tsColList: [tsCol]
    end
    
    // Check timestamp column
    if (any(tsColList, isNull)) do
      msg: "Invalid timestmap column(s) for handle " + handleErrString(handle) + "."
      logErr("csvImportHistory", msg)
      throw msg
    end
    
    // Get points of interest and map/check column names
    points = points
      .toRecList
      .findAll(p => p.has("csvColumn"))
      .map(p => p.set("csvColumnMatched", mapCsvColName(p->csvColumn, headers)))
    
    // Keep CSV headers: timestamp + CSV data column names from point metadata
    keepHeaders: tsColList.addAll(points.map() p => p["csvColumnMatched"]).removeNull
      
    // Subset to needed columns
    data = data.keepCols(keepHeaders)
    
    // Consolidate composite timestamp to single column
    if (tsColList.size > 1) do
      try do
        // Create composite column
        data = data
          .addCol(tsCol, r => tsColList.map(col => r[col]).concat(" "))
          .removeCols(tsColList)
      catch (ex) do
        // If error, log, and rethrow error
        logErr("csvImportHistory", "Error concatenating multi-column timestamp for handle " + handleErrString(handle) + ".", ex)
        throw (ex)
      end
    end
     
    // Extract relevant data for each rec and store to Folio
    errorFound: false
    points = points.map() p => do
      // Catch and log any errors
      try do
        p = writePointHis(p, tsCol, p["csvColumnMatched"], data)
      catch (ex) do
        msg: "Error importing CSV history for point @" + p.toRecId.toStr + "."
        if (checked) do
          logErr("csvImportHistory", msg, ex)
          errorFound = true
        else if (not noWarn) do
          logWarn("csvImportHistory", msg, ex)
        end
        return null
      end
      return p
    end
  
    // Handle errors
    if (errorFound) throw "Errors occurred while importing CSV history from handle " + handleErrString(handle) + "; see log."
    
    // Preview mode
    if (preview != null) return points // <-- Will contain time series data
    
    // Re-read and return list of all affected recs
    points = points.removeNull
    if (points.isEmpty) do
      return null
    else do
      return points.toRecIdList.readByIds
    end
  end
---
name:csvImportPoints
doc:
  Imports point records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. The user-provided **spec**, if any, is merged with a [default column specification]`ext-nrelCsv::doc#entityImport` for importing points. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, noWarn:false}, opts)
    
    // Record template
    template: {point}
    if (opts.has("template")) do
      template = opts->template.merge(template)
      opts = opts.remove("template") // For downstream use by csvImportRecs
    end
    
    // Commit option
    commitRecs: opts.has("commit") and opts["commit"] != false
    opts = opts.merge({-commit}) // For downstream use by csvImportRecs
    
    // Other true/false options
    checked: opts.has("checked") and opts["checked"] != false
    log:     opts.has("log")     and opts["log"]     != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // CSV column specification
    defaultSpec: {
      pointName:          "string",
      pointTags:          "tags",
      equipName:          "string",
      equipRef:           "ref",
      siteName:           "string",
      siteRef:            "ref",
      spaceName:          "string",
      spaceRef:           "ref",
      weatherStationName: "string",
      weatherStationRef:  "ref",
      tz:                 "string",
      kind:               "string",
      unit:               "string"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
      
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, opts)
      
    // Process records
    recs: d.map() row => do
      // Merge common template
      row = row.merge(template)
      
      // Set point description
      row = row.set("navName", row["pointName"]).remove("pointName")
      
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro")) do
        // Weather points
        if (row.has("weatherStationRef") or row.has("weatherStationName")) do
          row = row.set("disMacro", "\$weatherStationRef \$navName")
        
        // Regular points
        else do
          row = row.set("disMacro", "\$equipRef \$navName")
        end
      end
      
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("siteName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
      
      // Map space
      try do
        row = row
          .set("spaceRef", getSpaceByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("spaceName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("spaceRef").remove("spaceName") // Clean up on failure
      end
      
      // Map equip
      try do
        row = row
          .set("equipRef", getEquipByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("equipName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("equipRef").remove("equipName") // Clean up on failure
      end
      
      // Map weather location
      try do
        row = row
          .set("weatherStationRef", getWeatherStationByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("weatherStationName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("weatherStationRef").remove("weatherStationName") // Clean up on failure
      end
      
      // Default timezone
      if (row.missing("tz")) do
        // Timezone source in priority order
        if (row.has("siteRef") and readById(row->siteRef).has("tz")) do
          // From site
          tz: readById(row->siteRef)->tz
          
        else if (row.has("weatherStationRef") and readById(row->weatherStationRef).has("tz")) do
          // From weather station
          tz: readById(row->weatherStationRef)->tz
          
        else do
          // Project default
          tz: now().tz
        end
        
        // Assign timezone
        row = row.set("tz", tz)
      end
      
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImporPoints")).commit
    else do
      return recs
    end
    
  end
---
name:csvImportRecs
doc:
  Imports records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  See the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects.
func
src:
  (handle, spec, opts:{}) => do
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////  
  
    // Default options
    opts = merge({
      sep:             " ",
      datePattern:     "YYYY-MM-DD",                            // Default from parseDate()
      timePattern:     "hh:mm:SS",                              // Default from parseTime()
      dateTimePattern: "YYYY-MM-DD'T'hh:mm:SS.FFFFFFFFFz zzzz", // Default from parseDateTime()
      checked:         true,
      commit:          false,
      safe:            true,
      log:             false,
      noWarn:          false
    }, opts)
  
    // Valid pass-through options for ioStreamCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])
    
    // True/false options
    checked:    opts.has("checked") and opts["checked"] != false
    commitRecs: opts.has("commit")  and opts["commit"]  != false
    safe:       opts.has("safe")    and opts["safe"]    != false
    log:        opts.has("log")     and opts["log"]     != false
    noWarn:     opts.has("noWarn")  and opts["noWarn"]  != false
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Helper Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Parse tag list
    parseTags: (s, checked:checked) => try do
      ("{" + delimConvert(s,opts->sep,",") + "}").parseDict(checked)
    catch (ex) do
      if (checked) throw (ex)
      return {} // Empty dict for compatibility with code below
    end
    
    // Parse coordinate
    parseCoordLocal: (v, checked) => delimConvert(v, opts->sep, ",").parseCoord(checked)
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Safe mode
    if (safe) do
      // Axon evaluation not permitted
      spec = spec.map() (v, n) => do
        if (v.lower == "axon") do
          if (not noWarn) do
            logWarn("csvImportRecs",
              "Axon data type not allowed in safe mode; column spec \""
              + n + "\" changed to to \"string\".")
          end
          return "string"
        else do
          return v
        end
      end
    end
     
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Row processing function
    mapCsvRow: (row) => do
      // Placeholder for output row
      tags: {}
  
      // Filter null and empty string input
      row = row.findAll(v => (v != null and v != ""))
  
      // Handle empty rows
      if (row.isEmpty) return null
      
      // Parse tags
      row.each() (v,n) => do
        // Check for column specification
        if (spec.has(n)) do
          if (spec[n].lower == "axon") do
            tags = tags.set(n, eval(v)) // Use with caution! Not allowed in safe mode.
          else if (spec[n].lower == "bool") do
            tags = tags.set(n, parseBool(v, checked))
          else if (spec[n].lower == "coord") do
            tags = tags.set(n, parseCoordLocal(v, checked))
          else if (spec[n].lower == "date") do
            tags = tags.set(n, parseDate(v, opts->datePattern, checked))
          else if (spec[n].lower == "datetime") do
            tags = tags.set(n, parseDateTime(v, opts->dateTimePattern, checked))
          else if (spec[n].lower == "ignore") do
            null // No action
          else if (spec[n].lower == "integer") do
            tags = tags.set(n, parseInt(v, 10, checked))
          else if (spec[n].lower == "marker") do
            tags = tags.set(n, marker())
          else if (spec[n].lower == "number") do
            tags = tags.set(n, parseNumber(v, checked))
          else if (spec[n].lower == "ref") do
            tags = tags.set(n, parseRef2(v, checked))
          else if (spec[n].lower == "string") do
            tags = tags.set(n, v)
          else if (spec[n].lower == "tags") do
            parseTags(v, checked).each((vv,nn) => tags = tags.set(nn,vv))
          else if (spec[n].lower == "time") do
            tags = tags.set(n, parseTime(v, opts->timePattern, checked))
          else if (spec[n].lower == "uri") do
            tags = tags.set(n, parseUri(v, checked))
          else do
            throw "Invalid specification for column " + n + ": " + spec[n]
          end
  
        // No column spec; use as is (defaults to string)
        else do
          tags = tags.set(n,v)
        end
      end
  
      // Merge user-supplied template
      if (opts.has("template")) tags = tags.merge(opts->template)
      
      // Return processed row of tags
      return tags
    end
    
    // Read and parse recs from file
    recs: ioStreamCsv(handle, ioOpts)
      .map(mapCsvRow)
      .collect(toGrid)
    
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImportRecs")).commit
    else do
      return recs
    end
  end
---
name:csvImportSites
doc:
  Imports site records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. The user-provided **spec**, if any, is merged with a [default column specification]`ext-nrelCsv::doc#entityImport` for importing sites. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, noWarn:false}, opts)
    
    // Record template
    template: {site}
    if (opts.has("template")) do
      template = opts->template.merge(template)
      opts = opts.remove("template") // For downstream use by csvImportRecs
    end
    
    // Commit option
    commitRecs: opts.has("commit") and opts["commit"] != false
    opts = opts.merge({-commit}) // For downstream use by csvImportRecs
    
    // Other true/false options
    checked: opts.has("checked") and opts["checked"] != false
    log:     opts.has("log")     and opts["log"]     != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // CSV column specification
    defaultSpec: {
      siteName:           "string",
      siteTags:           "tags",
      area:               "number",
      geoAddr:            "string",
      geoStreet:          "string",
      geoCity:            "string",
      geoState:           "string",
      geoCounty:          "string",
      geoCountry:         "string",
      geoPostalCode:      "string",
      geoCoord:           "coord",
      primaryFunction:    "string",
      tz:                 "string",
      weatherStationName: "string",
      weatherStationRef:  "ref",
      yearBuilt:          "number"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
    
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, opts)
      
    // Process records
    recs: d.map() row => do
      // Merge common template
      row = row.merge(template)
      
      // Set site description
      row = row.set("dis", row["siteName"]).remove("siteName")
  
      // Map weather location
      try do
        row = row
          .set("weatherStationRef", getWeatherStationByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("weatherStationName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("weatherStationRef").remove("weatherStationName") // Clean up on failure
      end
      
      // Default timezone
      if (row.missing("tz")) do
        // Timezone source in priority order
        if (row.has("weatherStationRef") and readById(row->weatherStationRef).has("tz")) do
          // From weather station
          tz: readById(row->weatherStationRef)->tz
        else do
          // Project default
          tz: now().tz
        end
        
        // Assign timezone
        row = row.set("tz", tz)
      end
      
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImportSites")).commit
    else do
      return recs
    end
    
  end
  
  // Potential starting point for future unit tests:
  // csvImportSites("siteName, siteTags, weatherStationRef, weatherStationName, floors\n\"My Site\",foo bar,,\"Denver, CO, United States\",3",{floors:"integer"},{template:{baz}})
---
name:csvImportSpaces
doc:
  Imports space records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. The user-provided **spec**, if any, is merged with a [default column specification]`ext-nrelCsv::doc#entityImport` for importing spaces. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, noWarn:false}, opts)
    
    // Record template
    template: {space}
    if (opts.has("template")) do
      template = opts->template.merge(template)
      opts = opts.remove("template") // For downstream use by csvImportRecs
    end
    
    // Commit option
    commitRecs: opts.has("commit") and opts["commit"] != false
    opts = opts.merge({-commit}) // For downstream use by csvImportRecs
    
    // Other true/false options
    checked: opts.has("checked") and opts["checked"] != false
    log:     opts.has("log")     and opts["log"]     != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // CSV column specification
    defaultSpec: {
      spaceName:    "string",
      spaceTags:    "tags",
      floor:        "marker",
      floorNum:     "integer",
      ground:       "marker",
      roof:         "marker",
      siteName:     "string",
      siteRef:      "ref",
      subterranean: "marker"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
      
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, opts)
      
    // Process records
    recs: d.map() row => do
      // Merge common template
      row = row.merge(template)
      
      // Set space description
      row = row.set("navName", row["spaceName"]).remove("spaceName")
      
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro")) do
        row = row.set("disMacro", "\$siteRef \$navName")
      end
      
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], noWarn))
          .remove("siteName")
      catch (ex) do
        if (checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
      
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImportSpaces")).commit
    else do
      return recs
    end
    
  end
  
  // Potential starting point for future unit tests:
  // csvImportSpaces("spaceName, spaceTags, floor, floorNum, siteName\n\"1st Floor\",ground,M,1,\"My Site\"",{},{})
---
name:csvImportWeatherStations
doc:
  Imports weather station records from CSV data provided by **handle**, parsing them according to the provided column specification dictionary **spec** and options **opts**. The user-provided **spec**, if any, is merged with a [default column specification]`ext-nrelCsv::doc#entityImport` for importing weather stations. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#import` for a full description of **spec** and **opts** and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, noWarn:false}, opts)
    
    // Record template
    template: {weatherStation}
    if (opts.has("template")) do
      template = opts->template.merge(template)
      opts = opts.remove("template") // For downstream use by csvImportRecs
    end
    
    // Commit option
    commitRecs: opts.has("commit") and opts["commit"] != false
    opts = opts.merge({-commit}) // For downstream use by csvImportRecs
    
    // Other true/false options
    checked: opts.has("checked") and opts["checked"] != false
    log:     opts.has("log")     and opts["log"]     != false
    noWarn:  opts.has("noWarn")  and opts["noWarn"]  != false
    
    // CSV column specification
    defaultSpec: {
      weatherStationName: "string",
      weatherStationTags: "tags",
      geoAddr:            "string",
      geoStreet:          "string",
      geoCity:            "string",
      geoState:           "string",
      geoCounty:          "string",
      geoCountry:         "string",
      geoPostalCode:      "string",
      geoCoord:           "coord",
      geoElevation:       "number",
      tz:                 "string"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
    
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, opts)
      
    // Process records
    recs: d.map() row => do
      // Merge common template
      row = row.merge(template)
      
      // Set site description
      row = row.set("dis", row["weatherStationName"]).remove("weatherStationName")
      
      // Default timezone
      if (row.missing("tz")) do
        // Project default
        tz: now().tz
        
        // Assign timezone
        row = row.set("tz", tz)
      end
      
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (commitRecs) do
      return recs.toRecList.map(csvAddRec(_, log, "csvImportWeatherStations")).commit
    else do
      return recs
    end
    
  end
---
name:delimConvert
doc:
  In a string, convert instances of one delimiter to another. Converts instances of delimiter character **old** in string **s** to **new** (default '","'), under the following rules:
    
  - If **old** equals **new**, **s** is returned unmodified 
  - Delimiters inside quoted strings are ignored
  - Escaped delimiters (instances of **old** prefixed by '\') are not converted, but the escape character '\' is stripped from the output
  - All other instances of **old** are changed to **new**
  - All other escaped characters are passed through as-is
  - Consecutive whitespace delimiters are combined
    
  If **old** is whitespace, then any whitespace character matches: space, '\t', '\n', '\r', '\f'.
   
  Examples
  --------
  
    "a b   c\td".delimConvert(" ")                  >> a,b,c,d
    "name:\"First Last\" age:34".delimConvert(" ")  >> name:"First Last",age:34
    "a;\"b;c\";c".delimConvert(";")                 >> a,"b;c",c
    r",\,,\".delimConvert(",","|")                  >> |,|\
    
  Enclosing quotes are omitted from example outputs.
func
src:
  (s, old, new:",") => do
    // Check delimiter sizes
    if (old.size > 1 or new.size > 1) do
      throw "Old and new delimiters must each be a single character."
    end
  
    // Trivial case
    if (old == new) return s
  
    // Using a whitespace delimiter?
    oldIsSpace: old[0].isSpace
  
    // Setup (flags)
    prev: null
    inEscape: false
    inQuotes: false
    
    // Delimiter mapping function
    mapDelims: (char) => do
      // Escape: handle on next pass (lookahead)
      if (char == "\\" and not inEscape) do
        inEscape = true
        out: []
      
      // Escaped escape character
      else if (char == "\\" and inEscape) do
        inEscape = false
        out: [prev, char]
      
      // Escaped quote
      else if (char == "\"" and inEscape) do
        inEscape = false
        out: [prev, char]
   
      // Unescaped quote
      else if (char == "\"") do
        inQuotes = not(inQuotes)
        out: [char]
  
      // Escaped delimiter: Strip escape
      else if (char == old and prev == "\\") do
        inEscape = false
        out: [char]
        
      // Inside quotes: As-is
      else if (inQuotes) do
        out: [char]
      
      // Any other escaped character: As-is (including escape)
      else if (inEscape) do
        inEscape = false
        out: [prev, char]
      
      // Unescaped whitespace delimiter: Replace
      else if (oldIsSpace and char[0].isSpace) do
        if (prev[0].isSpace) do
          // Combine consecutive whitespace
          out: []
        else do
          out: [new]
        end
      
      // Unescaped non-whitespace delimiter: Replace
      else if (char == old) do
        out: [new]
      
      // All other characters 
      else do
        out: [char]
      end
      
      // Update previous
      prev = char
      
      // Return
      return out
    end
    
    // Scan and map input to output buffer character-by-character
    buffer: (1..(s.size))
      .stream
      .flatMap(i => s[(i-1)].toChar.mapDelims)
      .collect
  
    // Handle edge case: s ends in unescaped \
    if (inEscape) buffer = buffer.add("\\")
    
    // Return
    return buffer.concat
  end
---
name:getEquipByRefOrName
func
nodoc
src:
  (rec, finder:null, noWarn:false) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
    
    // Optional hierarchical filters
    siteFilter: row => (rec["siteRef"] == null) or (row["siteRef"] == rec->siteRef)
    spaceFilter: row => (rec["spaceRef"] == null) or (row["spaceRef"] == rec->spaceRef)
    
    // Warn on conflict
    if (rec.has("equipRef") and rec.has("equipName") and not noWarn) do
      logWarn("getEquipByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'equipRef' and 'equipName'; " + 
        "'equipName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("equipRef")) do
      return readById(rec->equipRef).toRecId
  
    // Get by name
    else if (rec.has("equipName")) do
      // Search for matching spaces
      equips: readAll(equip)
        .findAll(siteFilter)
        .findAll(spaceFilter)
        .findAll(finder(_, rec->equipName))
  
      // Unique match?
      if (equips.size != 1) do
        throw "Could not make a unique match for equip " + rec["equipName"] +
          "; found " + equips.size + " records."
      else do
        return equips.first.toRecId
      end
  
    // Default
    else do
      return null
    end
  end
---
name:getSiteByRefOrName
func
nodoc
src:
  (rec, finder:null, noWarn:false) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
    
    // Warn on conflict
    if (rec.has("siteRef") and rec.has("siteName") and not noWarn) do
      logWarn("getSiteByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'siteRef' and 'siteName'; " + 
        "'siteName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("siteRef")) do
      return readById(rec->siteRef).toRecId
  
    // Get by name
    else if (rec.has("siteName")) do
      // Search for matching sites
      sites: readAll(site).findAll(finder(_, rec->siteName))
  
      // Unique match?
      if (sites.size != 1) do
        throw "Could not make a unique match for site " + rec["siteName"] +
          "; found " + sites.size + " records."
      else do
        return sites.first.toRecId
      end
    
    // Default
    else do
      return null
    end
  end
---
name:getSpaceByRefOrName
func
nodoc
src:
  (rec, finder:null, noWarn:false) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
    
    // Optional hierarchical filters
    siteFilter: row => (rec["siteRef"] == null) or (row["siteRef"] == rec->siteRef)
    
    // Warn on conflict
    if (rec.has("spaceRef") and rec.has("spaceName") and not noWarn) do
      logWarn("getSpaceByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'spaceRef' and 'spaceName'; " + 
        "'spaceName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("spaceRef")) do
      return readById(rec->spaceRef).toRecId
  
    // Get by name
    else if (rec.has("spaceName")) do
      // Search for matching spaces
      spaces: readAll(space)
        .findAll(siteFilter)
        .findAll(finder(_, rec->spaceName))
  
      // Unique match?
      if (spaces.size != 1) do
        throw "Could not make a unique match for space " + rec["spaceName"] +
          "; found " + spaces.size + " records."
      else do
        return spaces.first.toRecId
      end
    
    // Default
    else do
      return null
    end
  end
---
name:getWeatherStationByRefOrName
func
nodoc
src:
  (rec, finder:null, noWarn:false) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
    
    // Warn on conflict
    if (rec.has("weatherStationRef") and rec.has("weatherStationName") and not noWarn) do
      logWarn("getWeatherStationByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'weatherStationRef' and 'weatherStationName'; " + 
        "'weatherStationName' will be ignored.")
    end
    
    // Get by ref
    if (rec.has("weatherStationRef")) do
      return readById(rec->weatherStationRef).toRecId
  
    // Get by name
    else if (rec.has("weatherStationName")) do
      // Search for matching weather stations
      weatherStations: readAll(weatherStation).findAll(finder(_, rec->weatherStationName))
  
      // Unique match?
      if (weatherStations.size != 1) do
        throw "Could not make a unique match for weather station " + rec["weatherName"] +
          "; found " + weatherStations.size + " records."
      else do
        return weatherStations.first.toRecId
      end
      
    // Default
    else do
      return null
    end
  end
---
name:parseAuto
doc:
  Parse a Str **val**, automatically guessing its data type. Supports all [Zinc]`docHaystack::Zinc` data types plus the following keywords:
  
  - True: 'true', 'True', or 'TRUE' (as Bool)
  - False: 'false, 'False', or 'FALSE' (as Bool)
  - Null: 'null', 'Null', or 'NULL'
  - NA: 'na', 'Na', or 'NA'
  - Not a Number (NaN): 'nan', 'NaN', or 'NAN'
  - Positive Infinity: '+inf', '+Inf', or '+INF'
  - Negative Infinity: '-inf', '-Inf', or '-INF'
  
  For everything else, this function wraps `ioReadZinc`. The resulting parsing behavior supports most basic [Axon]`docHaxall::AxonLang` data types, but ranges, triple-quoted string literals, and raw string literals are not supported.
  
  If parsing fails and **checked** is 'false' returns null; otherwise throws an error.
func
src:
  (val, checked:true) => do
    // Try block
    try do
      // Check input
      if (not val.isStr) throw "'val' must a string."
      if (val.contains("\n")) throw "'val' must not contain newline characters."
  
      // Keywords: True, False, Null, NA, NaN, +Inf, -Inf
      if (val == "true"  or val == "True"  or val == "TRUE" ) return true
      if (val == "false" or val == "False" or val == "FALSE") return false
      if (val == "null"  or val == "Null"  or val == "NULL" ) return null
      if (val == "na"    or val == "Na"    or val == "NA"   ) return na()
      if (val == "nan"   or val == "NaN"   or val == "NAN"  ) return nan()
      if (val == "+inf"  or val == "+Inf"  or val == "+INF" ) return posInf()
      if (val == "-inf"  or val == "-Inf"  or val == "-INF" ) return negInf()
  
      // Parse using ZINC grammar
      return ioReadZinc("ver:\"3.0\"\nval\n" + val).first["val"] 
    
    // Catch block
    catch (ex) do
      if (checked) throw (ex)
      return null
    end
    
    // TO DO: Unit test(s)
    // parseAuto("{a, b:0kW, c:[1, 2, 5], d:\"Three sir!\", e:{foo bar:\"baz\"}}")
  end
---
name:parseCoord
doc:
  Parse a Coord **val**, which must consist of two number values separated by a comma. If parsing fails and checked = 'false' returns null; otherwise throws an error.
  
  - Numbers must be within the valid range per `coord`
  - Numbers cannot have a unit
  - Negative numbers must be preceded by '-'
  - Enclosing parentheses '( )' are optional
  - Spaces, tabs, and any preceding non-digit characters are ignored
  
  Examples:
  
    parseCoord("-42,105")                >> C(-42, 105)
    parseCoord("coord(40.689, -74.044)") >> C(40.689, -74.044)
func
src:
  (val, checked:true) => do
    // Try block
    try do
      // Check for string
      if (not val.isStr) throw "'val' must be a string."
         
      // Verify format: ignores preceding non-digits, whitespace, parens; handles negatives
      // Try it out here: https://regex101.com/r/nXRx8d/1
      regex: r"(?:[\D&&[^\-]]|\-\D)*(\-?\d+\.?\d*)\s*,\s*(\-?\d+\.?\d*)\)?\s*"
      if (not reMatches(regex, val)) throw "Invalid format for 'val': \"" + val + "\""
      
      // Parse from groups
      parts: reGroups(regex, val)
      return coord(parseFloat(parts[1]), parseFloat(parts[2]))
    
    // Catch block
    catch (ex) do
      if (checked) throw (ex)
      return null
    end
  end
---
name:parseDict
doc:
  Parse a Str **val** as a dict, which must be encoded as a valid [Zinc]`docHaystack::Zinc` dictionary. Because this function wraps `ioReadZinc`, it requires Zinc-style syntax rather than [Axon]`docHaxall::AxonLang` syntax for the following data types:
  
  - Null: 'N' instead of 'null'
  - Boolean: 'T/F' instead of 'true/false'
  
  Also, ranges, triple-quoted string literals, and raw string literals are not supported.
  
  If parsing fails and **checked** is 'false' returns null; otherwise throws an error.
func
src:
  (val, checked:true) => do
    // Try block
    try do
      // Check input
      if (not val.isStr) throw "'val' must a string."
      if (val.contains("\n")) throw "'val' must not contain newline characters."
      
      // Trim
      val = val.trim
  
      // Verify correct structure for a dict via regex
      if (not(reMatches(r"\{.*\}", val))) do
        throw "'val' must begin with \"{\" and end with \"}\"."
      end
  
      // Parse using Zinc grammar
      val = ioReadZinc("ver:\"3.0\"\nval\n" + val).first["val"]
      
      // Verify dict
      if (not(val.isDict)) throw "'val' does not parse as a valid dict."
      
      // Return
      return val
      
    // Catch block
    catch (ex) do
      if (checked) throw (ex)
      return null
    end
  end
