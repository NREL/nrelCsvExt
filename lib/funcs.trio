name:csvAddRec
func
nodoc
src:
  (rec, log, from:"csvAddRec") => do
    // Remove null tags
    rec = rec.removeNull
  
    // Log an info message
    if (log) logInfo(from, "Importing record: " + rec.dis)
  
    // Construct a diff for database commit
    diff(null, rec, {add})
  end
---
name:csvExportHistory
doc:"For the specified 'points' and time 'span', read and export a history grid a CSV files at 'handle', optionally with some convenience processing. See the [CSV extension docs]`ext-nrelCsv::doc#exportHis` for implementation details, a list of options passed via 'opts' and their effects."
func
overridable
src:
  (points, span, handle, opts:{}) => do
  
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    opts = merge({
      clean:       false,
      headerUnits: true,
      interpolate: false,
      removeUnits: true
    }, opts)
    
    // T/F options
    opts = opts.set("clean",       opts.has("clean")       and opts["clean"]       != false)
    opts = opts.set("headerUnits", opts.has("headerUnits") and opts["headerUnits"] != false)
    opts = opts.set("interpolate", opts.has("interpolate") and opts["interpolate"] != false)
    opts = opts.set("removeUnits", opts.has("removeUnits") and opts["removeUnits"] != false)
    
    // Valid pass-through options for ioReadCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])
  
    // Preview
    preview: opts["preview"]
    if (preview == marker()) do
      preview = 10
    else if (preview != null and not preview.isNumber) do
      throw "'preview' option must be a number."
    end
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Helper Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Range cleaning
    if (opts->clean) do
      hisRangeCleanInternal: (src, point) => do
        // Skip if not numeric
        if (point["kind"] != "Number") return src
        
        // Get default value
        if (point.has("defVal")) do
          defVal: point->defVal
        else if (opts.has("defVal")) do
          defVal: opts->defVal
        else do
          defVal: null
        end
        
        // Get range
        minVal: if (point.has("minVal")) point->minVal else negInf()
        maxVal: if (point.has("maxVal")) point->minVal else posInf() 
  
        // No default value: remove
        if (defVal == null) do
          src = src.hisFindAll((v, t) => v != na() and v >= minVal.to(v) and v <= maxVal.to(v)) 
  
        // Default value: replace
        else do
          src = src.hisMap() (v, t) => do
            if (v == na() or (v >= minVal.to(v) and v <= maxVal.to(v))) do
              return v
            else do
              return defVal
            end
          end
        end
  
        // Return
        return src
      end
    else do
      hisRangeCleanInternal: (src, point) => src
    end
  
    // Internal function to roll up history only
    if (opts.has("interval")) do
      hisRollupInternal: (src, point) => do
        // Numeric
        if (point["kind"] == "Number") do
          return src.hisRollupAuto(opts->interval)
  
        // Boolean
        else if (point["kind"] == "Bool") do
          hisRollup(src, durTrue, opts->interval)
            .hisMap(v => (v.to(opts->interval) / opts->interval).as(""))
  
        // Unsupported
        else do
          throw "Unsupported rollup kind \"" + p["kind"] + "\" for point: " + p.dis
        end
      end
    else do
      hisRollupInternal: (src, point) => src
    end
      
    // Internal function to interpolate history
    if (opts->interpolate) do
      hisInterpolateInternal: (src) => src.hisInterpolate
    else do
      hisInterpolateInternal: (src) => src
    end
    
    // Internal function to remove units
    if (opts->removeUnits) do
      hisRemoveUnitsInternal: (src) => src.hisMap(v => if (v.isNumber) v.to("") else v)
    else do
      hisRemoveUnitsInternal: (src) => src
    end
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Export History
    ////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Dates to span
    span = span.toSpan
  
    // Read and pre-process data
    data: points
      .toRecList
      .map(p => p
        .hisRead(span, {-limit})
        .hisRangeCleanInternal(p)
        .hisRollupInternal(p)
        .hisRemoveUnitsInternal
      )
      .hisJoin
      .hisInterpolateInternal
      .hisClip
  
    // Column headers (descriptions)
    data.colNames.each() cn => do
      // Skip timestamp
      if (cn == "ts") return null // skip timestamp column
      
      // Get description
      metadata: data.col(cn).meta
      dis: metadata.dis
      
      // Append units
      if (opts->headerUnits and metadata.has("unit")) do
        dis = dis + " (" + metadata->unit + ")"
      end
      
      // Fix 'dis' (becomes column header)
      data = data.addColMeta(cn, {dis:dis, -disMacro})
    end
      
    // Format timestamps?
    if (opts.has("tsPattern")) do
      data = data.map() row => row.set("ts", row->ts.format(opts->tsPattern))
    end
    
    // Preview?
    if (preview != null) do
      return getSafe(data, 0..(preview))
    end
  
    // Write output
    data.ioWriteCsv(handle, ioOpts)
  end
---
name:csvImportEquips
doc:
  Imports equip records from CSV data provided by 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. The user-provided 'spec', if any, is merged with a [default column specification]`ext-nrelCsv::doc#equipColSpec` for importing equips. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
overridable
src:
  (handle, spec:null, opts:{}) => do
    
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, warn:true}, opts)
    
    // Record template
    template: {equip}
    if (opts.has("template")) template = opts->template.merge(template)
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false)
    
    // Downstream options for csvImportRecs()
    downstreamOpts: opts.merge({commit:false, template:template})
  
    // CSV column specification
    defaultSpec: {
      dis:       "string",
      navName:   "string",
      equipTags: "tags",
      equipName: "string",
      equipRef:  "ref",
      siteName:  "string",
      siteRef:   "ref",
      spaceName: "string",
      spaceRef:  "ref"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, downstreamOpts)
  
    // Process records
    recs: d.map() row => do
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("siteName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
  
      // Map space
      try do
        row = row
          .set("spaceRef", getSpaceByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("spaceName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("spaceRef").remove("spaceName") // Clean up on failure
      end
  
      // Equip nesting (if applicable)
      if (row.has("equipName") or row.has("equipRef")) do
        try do
          row = row
            .set("equipRef", getEquipByRefOrName(row, opts["matchRefsBy"], opts->warn))
            .remove("equipName")
        catch (ex) do
          if (opts->checked) throw ex
          row = row.remove("equipRef").remove("equipName") // Clean up on failure
        end
      end
      
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro") and row.has("navName")) do
        row = row.set("disMacro", "\$siteRef \$navName")
      end
  
      // Return processed record
      return row.removeNull
    end
  
     // Return or commit
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImportEquips")).commit
    else do
      return recs
    end
  
  end
---
name:csvImportHistory
doc:"Imports point history for specified 'points' from CSV data provided by 'handle' and writes imported data to the database. See the [CSV extension docs]`ext-nrelCsv::doc#importHis` for implementation details, including required tags and a list of options passed via 'opts'."
func
overridable
src:
  (points, handle, opts:{}) => do

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////

    // Default options
    opts = merge({
      checked:  true,
      warn:     true,
      tsColumn: "ts",
      tz:       now().tz
    }, opts)

    // T/F options
    opts = opts.set("checked",   opts.has("checked")   and opts["checked"]   != false)
    opts = opts.set("overwrite", opts.has("overwrite") and opts["overwrite"] != false)
    opts = opts.set("warn",      opts.has("warn")      and opts["warn"]      != false)

    // Span
    if (opts["span"] == null and opts->overwrite) do
      // If span is unspecified, never overwrite
      logWarn("csvImportHistory", "'span' option is null; ignoring 'overwrite' option.")
      opts = opts.set("overwrite", false)
    else if (opts["span"] != null) do
      // Normalize span
      opts = opts.set("span", opts->span.toSpan)
    end

    // Valid pass-through options for ioReadCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])

    // Preview
    preview: opts["preview"]
    if (preview == marker()) do
      preview = 10
    else if (preview != null and not preview.isNumber) do
      throw "'preview' option must be a number."
    end

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Helper Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////

    // Handle argument string for error messages
    handleErrString: (val) => do
      // Uri
      if (val.isUri) return "`" + val.toStr + "`"

      // Anything else (presumably a CSV-formatted string)
      msg: val.toStr
      if (msg.size > 100) do
        return "\"" + msg[0..99] + "..." + "\"" // Truncate
      else do
        return "\"" + msg + "\""
      end
    end

    // Map CSV column by name (string) or index (integer)
    mapCsvColName: (n, columns) => do
      // By index
      if (n.isNumber) return getSafe(columns, n)

      // By name
      n = n.toTagName
      if (columns.contains(n)) return n

      // Not found
      return null
    end

    // Parse timestamp
    parseTimestamp: (x, pattern, tz, checked) => try do
      // Default pattern
      if (pattern == null) do
        ts: parseDateTime(x)

      // User-specified pattern
      else if (pattern.isStr) do
        ts: parseDateTime(x, pattern, tz, checked)

      // Set of patterns
      else if (pattern.isList) do
        // Try patterns until one successed
        ts: pattern.eachWhile() (pat) => parseDateTime(x, pat, tz, false)

        // If none was successful, throw an exception
        if (ts == null) do
          throw "Unable to parse timestamp \"" + x + "\" using any of the specified patterns: " + pattern.toStr
        end

        // No-op (prevents if/else statement code parsing error)
        null

      // Unexpected pattern
      else do
        throw "Unexpected timestamp pattern: " + pattern.toStr + " [" + debugType(pattern) + "]"
      end

      // Output
      return ts

    catch (ex) do
      if (checked) throw(ex)
      return null
    end

    // Parse value
    parseValue: (x, kind, checked) => do
      // Trim whitespace
      x = x.trim

      // Parse value...

      // Empty?
      if (x.isEmpty) do
        return null

      // String
      else if (kind == "Str") do
        return x

      // Boolean
      else if (kind == "Bool") do
        // Attempt to parse as: Boolean, number, automatic
        val: parseBool(x, false)
        if (val.isNull) val = parseNumber(x, false)
        if (val.isNull) val = parseAuto(x, checked)

        // Boolean
        if (val.isBool) do
          return val

        // Number -> Boolean
        else if (val.isNumber and not val.isNaN) do
          return (val != 0)

        // Encoded NA or null
        else if (val.isNA or val.isNull)
          return val

        // Unsupported
        else do
          if (checked) throw "Unexpected kind for parsed value: " + val.toStr +
            " [" + debugType(val) + "]; expected Bool or Number"
          return na()
        end

      // Number
      else if (kind == "Number") do
        // Attempt to parse as: Number, automatic
        val: parseNumber(x, false)
        if (val.isNull) val = parseAuto(x, checked)

        // Number
        if (val.isNumber) do
          return val

        // Encoded NA or null
        else if (val.isNA or val.isNull)
          return val

        // Unsupported
        else do
          if (checked) throw "Unexpected kind for parsed value: " + val.toStr +
            " [" + debugType(val) + "]; expected Number"
          return na()
        end

      // Unsupported kind
      else do
        throw "Kind \"" + kind + "\" is not supported."
      end
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Write Point History to Folio
    //////////////////////////////////////////////////////////////////////////////////////////////////

    writePointHis: (point, timeCol, valCol, data, checked) => do
      // Check columns
      if (valCol == null or data.missing(valCol)) do
        throw "'csvColumn' for point @" + point.toRecId.toStr + " was not found in imported CSV data."
      end
      
      // Drop all but the two columns we need
      data = data.keepCols([timeCol, valCol])
      
      // Drop rows which have empty timestamp or data (with a warning)
      before: size(data)
      data = data.findAll() row => row.has(timeCol) and row.has(valCol)
      after: size(data)
      if (opts->warn and (after < before)) do
        logWarn("csvImportHistory", "Column '" + valCol + "': Dropped " + (before - after) +
          " rows of data that are missing a timestamp and/or value.")
      end

      // Parse according to point metadata
      data = data.map() row => {
        ts: parseTimestamp(row[timeCol], opts["tsPattern"], opts["tz"], checked),
        val: parseValue(row[valCol], point["kind"], checked)
      }
      
      // Drop incorrectly parsed rows (with a warning)
      before = size(data)
      data = data.findAll row => row.has("ts") and row.has("val")
      after = size(data)
      if (opts->warn and (after < before)) do
        logWarn("csvImportHistory", "Unable to parse " + (before - after) + " rows of data for column '" + valCol + "'.")
      end
      
      // Return if empty (with a warning)
      if (data.isEmpty) do
        if (opts->warn and (after < before)) do
          logWarn("csvImportHistory", "Grid for column '" + valCol + "' is empty after parsing.")
        end
        return null
      end
      
      // Apply units
      if (point->kind=="Number" and point.has("csvUnit")) do
        data = data.hisMap() v => if (v.isNA) v else v.as(point->csvUnit)
      end

      // Sort on timestamp
      data = data.sort("ts")

      // Apply callback function
      if (point.has("csvCallback")) do
        // Data for task
        taskInput: {
          data: data,
          point: point,
          callbackExpr: point->csvCallback
        }

        // Execute callback in ephemeral task
        data = taskRun(
          // Task expression
          (input) => do
            // Regex for validating callback function expression
            regexMatch: r"[a-z]\w*(\(.*\))?" // Matches "foo" or "foo(...)"
            regexName: r"\A[a-z]\w*" // Matches function name

            // Validate callback function
            if (not reMatches(regexMatch, input->callbackExpr)) do
              throw "Invalid syntax for callback function: " + input->callbackExpr
            else if (func(reFind(regexName, input->callbackExpr), false).isNull) do
              throw "Could not find callback function: " + reFind(regexName, input->callbackExpr)
            else do
              // Convert to function
              callback: eval(input->callbackExpr)
              if (not callback.isFunc) do
                throw "Callback expression did not evaluate to a function: " + input->callbackExpr
              end
            end

            // Apply callback
            callback(input->data, input->point)
          end,
          taskInput // Passes data to task
        ).futureGet
      end

      // Apply value conversion
      if (point.has("csvConvert")) do
        // Apply point conversion
        data = data.hisMap() v => if (v.isNA) v else pointConvert(point, point->csvConvert, v)
      end

      // Apply rollup function
      if (point.has("csvRollupInterval")) do
        // User-specified rollup function
        if (point.has("csvRollupFunc")) do
          // Data for task
          taskInput: {
            data: data,
            rollupFunc: func(point->csvRollupFunc)->name.eval, // Safe way to get rollup function
            interval: point->csvRollupInterval
          }

          // Execute rollup in ephemeral task
          data = taskRun(
            // Task expression
            (input) => do
              hisRollup(input->data, input->rollupFunc, input->interval)
            end,
            taskInput // Passes data to task
          ).futureGet

        // Automatic rollup function 
        else do
          // Data for task
          taskInput: {
            data: data.addColMeta("val", point),
            interval: point->csvRollupInterval
          }

          // Execute rollup in ephemeral task
          data = taskRun(
            // Task expression
            (input) => do
              hisRollupAuto(input->data, input->interval)
            end,
            taskInput // Passes data to task
          ).futureGet
        end

        // Drop rows for which rollup function produced null data
        data = data.findAll() row => row.has("ts") and row.has("val")

        // Return if empty (no new data)
        if (data.isEmpty) return null
      end

      // Convert to SkySpark units
      if (point->kind=="Number") do
        data = data.hisMap() v => if (v.isNA) v else v.to(point["unit"])
      end

      // Convert from input timezone to point timezone
      if (point.has("tz")) do
        data = data.map() row => row.set("ts", (row->ts).toTimeZone(point->tz))
      end

      // Drop any data outside of span
      if (opts.has("span")) do
        data = data.findAll() row => (row->ts >= opts->span.start) and (row->ts <= opts->span.end)
      end

      // Drop any data for which the point already has history
      if (point.has("hisEnd") and not opts->overwrite) do
        data = data.findAll() row => (row->ts > point->hisEnd)
      end

      // Return if empty (no new data)
      if (data.isEmpty) return null

      // Preview?
      if (preview != null) do
        data = data
          .addMeta({hisStart:data.first->ts, hisEnd:data.last->ts})
          .addColMeta("val", point)
        return getSafe(data, 0..(preview))
      end

      // Write history to point
      if (opts->warn) do
        data.hisWrite(point)
      else do
        data.hisWrite(point, {noWarn}) // Suppress warnings
      end

      // Return processed point id
      return {id:point["id"]}
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read CSV
    try do
      data: ioReadCsv(handle, ioOpts)
      headers: colNames(data)
    catch (ex) do
      // If error, log, and rethrow error
      logErr("csvImportHistory", "Error importing CSV from provided handle: " + handleErrString(handle), ex)
      throw (ex)
    end

    // Timestamp column name
    if (opts->tsColumn.isList) do
      // Composite timestamp
      tsColList: (opts->tsColumn).map(n => n.mapCsvColName(headers))
      tsCol:     tsColList.concat("_")
    else do
      // Simple timestamp
      tsCol:     opts->tsColumn.mapCsvColName(headers)
      tsColList: [tsCol]
    end

    // Check timestamp column
    if (any(tsColList, isNull)) do
      msg: "Invalid timestmap column(s) for handle " + handleErrString(handle) + "."
      logErr("csvImportHistory", msg)
      throw msg
    end

    // Get points of interest and map/check column names
    points = points
      .toRecList
      .findAll(p => p.has("csvColumn"))
      .map(p => p.set("csvColumnMatched", mapCsvColName(p->csvColumn, headers)))

    // Require task extension (callbacks and rollups)
    if (read(ext=="task", false).isNull) do
      // Need task extension?
      needTask: 
        points.any(p => p["csvCallback"] != null) or // callbacks
        points.any(p => p["csvRollupInterval"] != null) // rollups

      // Throw error if we need tasks but don't have them
      if (needTask) do
        throw "To use 'csvCallback' or 'csvRollupInterval', " +
          "the task extension must be loaded."
      end
    end

    // Keep CSV headers: timestamp + CSV data column names from point metadata
    keepHeaders: tsColList.addAll(points.map() p => p["csvColumnMatched"]).removeNull

    // Subset to needed columns
    data = data.keepCols(keepHeaders)

    // Consolidate composite timestamp to single column
    if (tsColList.size > 1) do
      try do
        // Create composite column
        data = data
          .addCol(tsCol, r => tsColList.map(col => r[col]).concat(" "))
          .removeCols(tsColList)
      catch (ex) do
        // If error, log, and rethrow error
        logErr("csvImportHistory", "Error concatenating multi-column timestamp for handle " + handleErrString(handle) + ".", ex)
        throw (ex)
      end
    end

    // Extract relevant data for each rec and store to Folio
    errorFound: false
    points = points.toRecList.map() p => do
      // Catch and log any errors
      try do
        p = writePointHis(p, tsCol, p["csvColumnMatched"], data, opts->checked)
      catch (ex) do
        msg: "Error importing CSV history for point @" + p.toRecId.toStr + "."
        if (opts->checked) do
          logErr("csvImportHistory", msg, ex)
          errorFound = true
        else if (opts->warn) do
          logWarn("csvImportHistory", msg, ex)
        end
        return null
      end
      return p
    end

    // Handle errors
    if (errorFound) throw "Errors occurred while importing CSV history from handle " + handleErrString(handle) + "; see log."

    // Check for empty result
    points = points.removeNull
    if (points.isEmpty) return null

    // Preview mode
    if (preview != null) return points.hisJoin // <-- Will contain time series data

    // Re-read and return list of all affected recs
    return points.toRecIdList.readByIds
  end
---
name:csvImportPoints
doc:
  Imports point records from CSV data provided by 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. The user-provided 'spec', if any, is merged with a [default column specification]`ext-nrelCsv::doc#pointColSpec` for importing points. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
overridable
src:
  (handle, spec:null, opts:{}) => do
    
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, warn:true, tz:now().tz}, opts)
    
    // Record template
    template: {point}
    if (opts.has("template")) template = opts->template.merge(template)
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false)
  
    // Downstream options for csvImportRecs()
    downstreamOpts: opts.merge({commit:false, template:template})
  
    // CSV column specification
    defaultSpec: {
      dis:                "string",
      navName:            "string",
      pointTags:          "tags",
      equipName:          "string",
      equipRef:           "ref",
      siteName:           "string",
      siteRef:            "ref",
      spaceName:          "string",
      spaceRef:           "ref",
      weatherStationName: "string",
      weatherStationRef:  "ref",
      tz:                 "string",
      kind:               "string",
      unit:               "string"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Read from CSV
    d: csvImportRecs(handle, spec, downstreamOpts)
  
    // Process records
    recs: d.map() row => do
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("siteName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
  
      // Map space
      try do
        row = row
          .set("spaceRef", getSpaceByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("spaceName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("spaceRef").remove("spaceName") // Clean up on failure
      end
  
      // Map equip
      try do
        row = row
          .set("equipRef", getEquipByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("equipName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("equipRef").remove("equipName") // Clean up on failure
      end
  
      // Map weather station
      try do
        row = row
          .set("weatherStationRef", getWeatherStationByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("weatherStationName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("weatherStationRef").remove("weatherStationName") // Clean up on failure
      end
      
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro") and row.has("navName")) do
        // Weather points
        if (row.has("weatherStationRef")) do
          row = row.set("disMacro", "\$weatherStationRef \$navName")
  
        // Regular points
        else if (row.has("equipRef")) do
          row = row.set("disMacro", "\$equipRef \$navName")
        end
      end
      
      // Default timezone
      if (row.missing("tz")) do
        // Get site and weatherStation records
        parentSite: readById(row["siteRef"], false)
        parentWeatherStation: readById(row["weatherStationRef"], false)
      
        // Timezone source in priority order
        if (parentSite != null and parentSite.has("tz")) do
          // From site
          tz: parentSite->tz
  
        else if (parentWeatherStation != null and parentWeatherStation.has("tz")) do
          // From weather station
          tz: parentWeatherStation->tz
  
        else do
          // Default timezone
          tz: opts->tz
        end
  
        // Assign timezone
        row = row.set("tz", tz)
      end
  
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImporPoints")).commit
    else do
      return recs
    end
  
  end
---
name:csvImportRecs
doc:
  Imports records from CSV data at 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  See the [extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects.
func
overridable
src:
  (handle, spec, opts:{}) => do
  
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    opts = merge({
      sep:             " ",
      datePattern:     "YYYY-MM-DD",                            // Default from parseDate()
      timePattern:     "hh:mm:SS",                              // Default from parseTime()
      dateTimePattern: "YYYY-MM-DD'T'hh:mm:SS.FFFFFFFFFz zzzz", // Default from parseDateTime()
      tz:              now().tz,
      checked:         true,
      commit:          false,
      log:             false,
      warn:            true
    }, opts)
  
    // Valid pass-through options for ioStreamCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false) // Not used here
  
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Helper Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Parse tag list
    parseTags: (s, checked) => try do
      ("{" + delimConvert(s,opts->sep,",") + "}").parseDict(checked)
    catch (ex) do
      if (checked) throw (ex)
      return {} // Empty dict for compatibility with code below
    end
    
    // Parse coordinate
    parseCoordLocal: (v, checked) => delimConvert(v, opts->sep, ",").parseCoord(checked)
    
    // Parse ref
    parseRefLocal: (v, checked) => do
      // Trim whitespace
      v = v.trim
      
      // Parse with 'dis'
      if (v.contains(" ")) do
        splitAt: v.index(" ")
        ref: v[0..(splitAt-1)] // Ref
        dis: v[(splitAt+1)..-1] // Description
        parseRef(ref, dis, checked)
              
      // Parse without 'dis'
      else do
        parseRef(v, null, checked)
      end
    end
    
    // Parse uri
    parseUriLocal: (v, checked) => do
      // Strip leading/trailing `
      if (v.startsWith("`") and v.endsWith("`")) do
        if (v.size > 2) do
          v = v[1..-2]
        else if (checked) do
          throw "Unable to parse uri from string: \"" + v + "\""
        else do
          return null
        end
      end
      
      // Parse
      parseUri(v, checked)
    end
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    ////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Row processing function
    mapCsvRow: (row) => do
      // Placeholder for output record
      tags: {}
  
      // Filter null and empty string input
      row = row.findAll(v => (v != null and v != ""))
  
      // Handle empty rows
      if (row.isEmpty) return null
  
      // Parse tags
      row.each() (v,n) => do
        // Check for column specification
        if (spec.has(n)) do
          if (spec[n].lower == "auto") do
            tags = tags.set(n, parseAuto(v, opts->checked))
          else if (spec[n].lower == "bool") do
            tags = tags.set(n, parseBool(v, opts->checked))
          else if (spec[n].lower == "coord") do
            tags = tags.set(n, parseCoordLocal(v, opts->checked))
          else if (spec[n].lower == "date") do
            tags = tags.set(n, parseDate(v, opts->datePattern, opts->checked))
          else if (spec[n].lower == "datetime") do
            tags = tags.set(n, parseDateTime(v, opts->dateTimePattern, opts->tz, opts->checked))
          else if (spec[n].lower == "dict") do
            tags = tags.set(n, parseDict(v, opts->checked))
          else if (spec[n].lower == "float") do
            tags = tags.set(n, parseFloat(v, opts->checked))
          else if (spec[n].lower == "ignore") do
            null // No action
          else if (spec[n].lower == "integer") do
            tags = tags.set(n, parseInt(v, 10, opts->checked))
          else if (spec[n].lower == "list") do
            tags = tags.set(n, parseList(v, opts->checked))
          else if (spec[n].lower == "marker") do
            tags = tags.set(n, marker())
          else if (spec[n].lower == "number") do
            tags = tags.set(n, parseNumber(v, opts->checked))
          else if (spec[n].lower == "ref") do
            tags = tags.set(n, parseRefLocal(v, opts->checked))
          else if (spec[n].lower == "string") do
            tags = tags.set(n, v)
          else if (spec[n].lower == "tags") do
            parseTags(v, opts->checked).each((vv,nn) => tags = tags.set(nn,vv))
          else if (spec[n].lower == "time") do
            tags = tags.set(n, parseTime(v, opts->timePattern, opts->checked))
          else if (spec[n].lower == "uri") do
            tags = tags.set(n, parseUriLocal(v, opts->checked))
          else do
            throw "Invalid specification for column " + n + ": " + spec[n]
          end
  
        // No column spec; use as is (defaults to string)
        else do
          tags = tags.set(n, v)
        end
      end
  
      // Merge user-supplied template
      if (opts.has("template")) tags = tags.merge(opts->template)
  
      // Return processed row of tags
      return tags
    end
  
    // Read and parse recs from file
    recs: ioStreamCsv(handle, ioOpts)
      .map(mapCsvRow)
      .collect(toGrid)
  
    // Commit or return records
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImportRecs")).commit
    else do
      return recs
    end
  end
---
name:csvImportSites
doc:
  Imports site records from CSV data provided by 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. The user-provided 'spec', if any, is merged with a [default column specification]`ext-nrelCsv::doc#siteColSpec` for importing sites. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
overridable
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, warn:true, tz:now().tz}, opts)
    
    // Record template
    template: {site}
    if (opts.has("template")) template = opts->template.merge(template)
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false)
    
    // Downstream options for csvImportRecs()
    downstreamOpts: opts.merge({commit:false, template:template})
  
    // CSV column specification
    defaultSpec: {
      dis:                "string",
      siteTags:           "tags",
      area:               "number",
      geoAddr:            "string",
      geoStreet:          "string",
      geoCity:            "string",
      geoCounty:          "string",
      geoState:           "string",
      geoCountry:         "string",
      geoPostalCode:      "string",
      geoCoord:           "coord",
      geoElevation:       "number",
      primaryFunction:    "string",
      tz:                 "string",
      weatherStationName: "string",
      weatherStationRef:  "ref",
      yearBuilt:          "number"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, downstreamOpts)
  
    // Process records
    recs: d.map() row => do
      // Map weather station
      try do
        row = row
          .set("weatherStationRef", getWeatherStationByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("weatherStationName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("weatherStationRef").remove("weatherStationName") // Clean up on failure
      end
      
      // Site nesting (if applicable)
      if (row.has("siteName") or row.has("siteRef")) do
        try do
          row = row
            .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], opts->warn))
            .remove("siteName")
        catch (ex) do
          if (opts->checked) throw ex
          row = row.remove("siteRef").remove("siteName") // Clean up on failure
        end
      end
      
      // Default timezone
      if (row.missing("tz")) do
        // Get site and weatherStation records
        parentWeatherStation: readById(row["weatherStationRef"], false)
      
        // Timezone source in priority order
        if (parentWeatherStation != null and parentWeatherStation.has("tz")) do
          // From weather station
          tz: parentWeatherStation->tz
  
        else do
          // Default timezone
          tz: opts->tz
        end
  
        // Assign timezone
        row = row.set("tz", tz)
      end
  
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImportSites")).commit
    else do
      return recs
    end
  
  end
---
name:csvImportSpaces
doc:
  Imports space  records from CSV data provided by 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. The user-provided 'spec', if any, is merged with a [default column specification]`ext-nrelCsv::doc#spaceColSpec` for importing spaces. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
overridable
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, warn:true}, opts)
    
    // Record template
    template: {space}
    if (opts.has("template")) template = opts->template.merge(template)
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false)
    
    // Downstream options for csvImportRecs()
    downstreamOpts: opts.merge({commit:false, template:template})
  
    // CSV column specification
    defaultSpec: {
      dis:          "string",
      navName:      "string",
      spaceTags:    "tags",
      area:         "number",
      floor:        "marker",
      floorNum:     "integer",
      ground:       "marker",
      room:         "marker",
      roof:         "marker",
      siteName:     "string",
      siteRef:      "ref",
      spaceName:    "string",
      spaceRef:     "ref",
      subterranean: "marker",
      zone:         "marker"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, downstreamOpts)
  
    // Process records
    recs: d.map() row => do
      // Map site
      try do
        row = row
          .set("siteRef", getSiteByRefOrName(row, opts["matchRefsBy"], opts->warn))
          .remove("siteName")
      catch (ex) do
        if (opts->checked) throw ex
        row = row.remove("siteRef").remove("siteName") // Clean up on failure
      end
  
      // Space nesting (if applicable)
      if (row.has("spaceName") or row.has("spaceRef")) do
        try do
          row = row
            .set("spaceRef", getSpaceByRefOrName(row, opts["matchRefsBy"], opts->warn))
            .remove("spaceName")
        catch (ex) do
          if (opts->checked) throw ex
          row = row.remove("spaceRef").remove("spaceName") // Clean up on failure
        end
      end
  
      // Default disMacro
      if (row.missing("dis") and row.missing("disMacro") and row.has("navName")) do
        row = row.set("disMacro", "\$siteRef \$navName")
      end
  
      // Return processed record
      return row.removeNull
    end
  
    // Return or commit
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImportSpaces")).commit
    else do
      return recs
    end
  
  end
---
name:csvImportWeatherStations
doc:
  Imports weather station records from CSV data provided by 'handle', parsing them according to the provided column 'spec' (specification) and options 'opts'. The user-provided 'spec', if any, is merged with a [default column specification]`ext-nrelCsv::doc#weatherStationColSpec` for importing weather stations. Returns a grid of dicts ready to commit as Folio records. If option 'commit' is enabled, also commits the records to the Folio.
  
  - See `csvImportRecs` and the [CSV extension docs]`ext-nrelCsv::doc#importRecs` for a full description of 'spec' and 'opts' and their effects
  - See [entity-specific import]`ext-nrelCsv::doc#entityImport` for other implementation details
func
overridable
src:
  (handle, spec:null, opts:{}) => do
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Default options
    // These should always match csvImportRecs() defaults but are also needed locally
    opts = merge({checked:true, commit:false, log:false, warn:true, tz:now().tz}, opts)
    
    // Record template
    template: {weatherStation}
    if (opts.has("template")) template = opts->template.merge(template)
    
    // T/F options
    opts = opts.set("checked", opts.has("checked") and opts["checked"] != false)
    opts = opts.set("commit",  opts.has("commit")  and opts["commit"]  != false)
    opts = opts.set("log",     opts.has("log")     and opts["log"]     != false)
    opts = opts.set("warn",    opts.has("warn")    and opts["warn"]    != false)
    
    // Downstream options for csvImportRecs()
    downstreamOpts: opts.merge({commit:false, template:template})
  
    // CSV column specification
    defaultSpec: {
      dis:                "string",
      weatherStationTags: "tags",
      geoAddr:            "string",
      geoStreet:          "string",
      geoCity:            "string",
      geoCounty:          "string",
      geoState:           "string",
      geoCountry:         "string",
      geoPostalCode:      "string",
      geoCoord:           "coord",
      geoElevation:       "number",
      tz:                 "string"
    }
    if (spec != null) do
      spec = merge(defaultSpec, spec)
    else do
      spec = defaultSpec
    end
  
    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////
  
    // Read from CSV
    d: csvImportRecs(handle, spec, downstreamOpts)
  
    // Process records
    recs: d.map() row => do
      // Default timezone
      if (row.missing("tz")) do
        row = row.set("tz", opts->tz)
      end
  
      // Return processed record
      return row.removeNull
    end
    
    // Return or commit
    if (opts->commit) do
      return recs.toRecList.map(csvAddRec(_, opts->log, "csvImportWeatherStations")).commit
    else do
      return recs
    end
  
  end
---
name:delimConvert
doc:
  In a string, convert instances of one delimiter to another. Converts instances of delimiter character 'old' in string 's' to 'new' (default '","'), under the following rules:
  
  - If 'old' equals 'new', 's' is returned unmodified
  - Delimiters inside quoted strings are ignored
  - Escaped delimiters (instances of 'old' prefixed by '\') are not converted, but the escape character '\' is stripped from the output
  - All other instances of 'old' are changed to 'new'
  - All other escaped characters are passed through as-is
  - Consecutive whitespace delimiters are combined
  
  If 'old' is whitespace, then any whitespace character matches: space, '\t', '\n', '\r', '\f'.
  
  Examples
  --------
  
    "a b   c\td".delimConvert(" ")                  >> a,b,c,d
    "name:\"First Last\" age:34".delimConvert(" ")  >> name:"First Last",age:34
    "a;\"b;c\";c".delimConvert(";")                 >> a,"b;c",c
    r",\,,\".delimConvert(",","|")                  >> |,|\
  
  Enclosing quotes are omitted from example outputs.
func
overridable
src:
  (s, old, new:",") => do
    // Check delimiter sizes
    if (old.size > 1 or new.size > 1) do
      throw "Old and new delimiters must each be a single character."
    end
  
    // Trivial case
    if (old == new) return s
  
    // Using a whitespace delimiter?
    oldIsSpace: old[0].isSpace
  
    // Setup (flags)
    prev: null
    inEscape: false
    inQuotes: false
  
    // Delimiter mapping function
    mapDelims: (char) => do
      // Escape: handle on next pass (lookahead)
      if (char == "\\" and not inEscape) do
        inEscape = true
        out: []
  
      // Escaped escape character
      else if (char == "\\" and inEscape) do
        inEscape = false
        out: [prev, char]
  
      // Escaped quote
      else if (char == "\"" and inEscape) do
        inEscape = false
        out: [prev, char]
  
      // Unescaped quote
      else if (char == "\"") do
        inQuotes = not(inQuotes)
        out: [char]
  
      // Escaped delimiter: Strip escape
      else if (char == old and prev == "\\") do
        inEscape = false
        out: [char]
  
      // Inside quotes: As-is
      else if (inQuotes) do
        out: [char]
  
      // Any other escaped character: As-is (including escape)
      else if (inEscape) do
        inEscape = false
        out: [prev, char]
  
      // Unescaped whitespace delimiter: Replace
      else if (oldIsSpace and char[0].isSpace) do
        if (prev[0].isSpace) do
          // Combine consecutive whitespace
          out: []
        else do
          out: [new]
        end
  
      // Unescaped non-whitespace delimiter: Replace
      else if (char == old) do
        out: [new]
  
      // All other characters
      else do
        out: [char]
      end
  
      // Update previous
      prev = char
  
      // Return
      return out
    end
  
    // Scan and map input to output buffer character-by-character
    buffer: (1..(s.size))
      .stream
      .flatMap(i => s[(i-1)].toChar.mapDelims)
      .collect
  
    // Handle edge case: s ends in unescaped \
    if (inEscape) buffer = buffer.add("\\")
  
    // Return
    return buffer.concat
  end
---
name:getEquipByRefOrName
func
nodoc
src:
  (rec, finder:null, warn:true) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
  
    // Optional hierarchical filters
    siteFilter: row => (rec["siteRef"] == null) or (row["siteRef"] == rec->siteRef)
    spaceFilter: row => (rec["spaceRef"] == null) or (row["spaceRef"] == rec->spaceRef)
  
    // Warn on conflict
    if (rec.has("equipRef") and rec.has("equipName") and warn) do
      logWarn("getEquipByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'equipRef' and 'equipName'; " +
        "'equipName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("equipRef")) do
      return readById(rec->equipRef).toRecId
  
    // Get by name
    else if (rec.has("equipName")) do
      // Search for matching spaces
      equips: readAll(equip)
        .findAll(siteFilter)
        .findAll(spaceFilter)
        .findAll(finder(_, rec->equipName))
  
      // Unique match?
      if (equips.size != 1) do
        throw "Could not make a unique match for equip " + rec["equipName"] +
          "; found " + equips.size + " records."
      else do
        return equips.first.toRecId
      end
  
    // Default
    else do
      return null
    end
  end
---
name:getSiteByRefOrName
func
nodoc
src:
  (rec, finder:null, warn:true) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
  
    // Warn on conflict
    if (rec.has("siteRef") and rec.has("siteName") and warn) do
      logWarn("getSiteByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'siteRef' and 'siteName'; " +
        "'siteName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("siteRef")) do
      return readById(rec->siteRef).toRecId
  
    // Get by name
    else if (rec.has("siteName")) do
      // Search for matching sites
      sites: readAll(site).findAll(finder(_, rec->siteName))
  
      // Unique match?
      if (sites.size != 1) do
        throw "Could not make a unique match for site " + rec["siteName"] +
          "; found " + sites.size + " records."
      else do
        return sites.first.toRecId
      end
  
    // Default
    else do
      return null
    end
  end
---
name:getSpaceByRefOrName
func
nodoc
src:
  (rec, finder:null, warn:true) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
  
    // Optional hierarchical filters
    siteFilter: row => (rec["siteRef"] == null) or (row["siteRef"] == rec->siteRef)
  
    // Warn on conflict
    if (rec.has("spaceRef") and rec.has("spaceName") and warn) do
      logWarn("getSpaceByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'spaceRef' and 'spaceName'; " +
        "'spaceName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("spaceRef")) do
      return readById(rec->spaceRef).toRecId
  
    // Get by name
    else if (rec.has("spaceName")) do
      // Search for matching spaces
      spaces: readAll(space)
        .findAll(siteFilter)
        .findAll(finder(_, rec->spaceName))
  
      // Unique match?
      if (spaces.size != 1) do
        throw "Could not make a unique match for space " + rec["spaceName"] +
          "; found " + spaces.size + " records."
      else do
        return spaces.first.toRecId
      end
  
    // Default
    else do
      return null
    end
  end
---
name:getWeatherStationByRefOrName
func
nodoc
src:
  (rec, finder:null, warn:true) => do
    // Find function
    if (finder == null) do
      // Using dis()
      finder = (row, val) => row.dis == val
    else if (finder.isStr) do
      // By matching a specific tag
      findTag: finder
      finder = (row, val) => row[findTag] == val
    else if (not finder.isFunc) do
      throw "Finder must be null, a string, or a function."
    end
    
    // Warn on conflict
    if (rec.has("weatherStationRef") and rec.has("weatherStationName") and warn) do
      logWarn("getWeatherStationByRefOrName",
        "Record \"" + rec.dis + "\" " +
        "has both 'weatherStationRef' and 'weatherStationName'; " +
        "'weatherStationName' will be ignored.")
    end
  
    // Get by ref
    if (rec.has("weatherStationRef")) do
      return readById(rec->weatherStationRef).toRecId
  
    // Get by name
    else if (rec.has("weatherStationName")) do
      // Search for matching weather stations
      weatherStations: readAll(weatherStation).findAll(finder(_, rec->weatherStationName))
  
      // Unique match?
      if (weatherStations.size != 1) do
        throw "Could not make a unique match for weather station " + rec["weatherStationName"] +
          "; found " + weatherStations.size + " records."
      else do
        return weatherStations.first.toRecId
      end
  
    // Default
    else do
      return null
    end
  end

