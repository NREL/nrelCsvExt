// Copyright (C) 2017, National Renewable Energy Laboratory
// All Rights Reserved

---
name:csvImportEquips
func
doc:
  Imports equip records from CSV data. Intended for use in tailored CSV import scripts.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of imported equip records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'dryrun': Marker; if present then records will be read and returned but not committed to the
    Folio
  - 'flag': string specifying the name of a marker tag to apply to the new records as a flag
  - 'log': Boolean indicating whether log entries should be made for each imported record
  - 'template': A CSV template for supplemental columns; see `csvReadRecs`
  
  If supplied, 'template' will be merged with the default template (see *Details*). In the case of
  conflicts, the user-specified template entries take precedence.
  
  In addition, valid options for `csvReadRecs` may be supplied and will be passed through.
  
  Details
  -------
  
  This function expects a CSV file with some or all of the following columns:
  
    Tag        | Type    | Description
    ---------- | ------- | ------------------------------------------
    equipName  | string  | Name of equip; used to set 'navName'
    equipTags  | taglist | Arbitrary list of tags to apply using Axon
    siteName   | string  | Name of site; used to construct 'siteRef'
               |         | by matching site name
    siteRef    | ref     | Site reference; silently overrides
               |         | 'siteName'
  
  This default template can be modified using the 'template' option. Other arbitrary column names
  are also supported and will import as strings. See `csvReadRecs` for the low-level import
  function.
  
  Notes
  -----
  
  1. All imported equips receive the 'equip' tag automatically. If an import 'flag' option is
     specified, imported equips receive it as a marker tag as well.
  2. 'equipName' and either 'siteName' or 'siteRef' are required; other columns are optional.
  3. If the function is unable to make a unique match to an existing site using 'siteName', it will
     throw an error.
  4. Parsing failures will throw an error. In the event of a parsing failure, check the CSV data
     for errors.
src:
  (uri, opts:{}) => do

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({log:true}, opts)

    // Tags to add
    addTags: {equip}
    if (opts.has("flag")) addTags = addTags.set(opts->flag, marker())

    // CSV Template
    template: {
      equipName:"string",
      equipTags:"taglist",
      siteName:"string",
      siteRef:"ref"
    }
    if (opts.has("template")) template = merge(template, opts->template)

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Add new record
    addRec: (msg, tags) => do

      // Remove null tags
      tags = tags.findAll v => v != null

      // Log an info message
      if (opts->log) logInfo("import", msg)

      // Add as new record to the database
      commit(diff(null, tags, {add}))
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read from CSV
    d: csvReadRecs(uri, template, opts)

    // Process records and commit to database
    d.map() row => do
      // Add universal tags
      row = union(row, addTags)

      // Map site
      if (row.has("siteRef")) do
        siteMatch: readById(row->siteRef, false)
        if (siteMatch == null) throw "Matching site record not found."
        row = row.remove("siteName")

      end else if (row.has("siteName")) do
        siteMatch: readAll(site and dis==row["siteName"])
        if (siteMatch.size != 1) do
          throw "Could not make a unique match for site " + row["siteName"] +
            "; found " + siteMatch.size + " records."
        else do
          row = row.set("siteRef", siteMatch.first->id).remove("siteName")
        end
        
      end else do
        throw "Either 'siteName' or 'siteRef' is required."
      end
      
      // Set equip navName and disMacro
      row = row
        .set("navName", row["equipName"])
        .set("disMacro", "\$siteRef \$navName")
        .remove("equipName")

      // Commit
      if (opts.has("dryrun")) do
        return row
      else do
        return addRec("Importing equip " + row.dis, row)
      end
    end

  end
---
name: csvImportHistory
func
doc:
  Imports time series data from a CSV file and writes it to point histories. Intended for use in
  tailored CSV import scripts.

  Parameters
  ----------
  
  - **recs:** List or grid of point records which will receive the imported history
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of points with new or modified history.
  
  Options
  -------
  
  The following options are supported:
  
  - 'checked': Check parsing failures?
    - If *true*, parsing failures will produce an error
    - If *false* (default), parsing failures will only log a warning
  - 'tsColumn': Name or index of the CSV time stamp column (default = "ts")
  - 'tsPattern': String or list of strings specifying one or more patterns to use for parsing the
    time stamps in the CSV data (default = "YYYY-MM-DD hh:mm:ss"); see `parseDateTime`
  - 'tz': Time zone in which to interpret the time stamp (default = the project time zone)
  
  In addition, valid options for `ioReadCsv` may be supplied and will be passed through.
  
  Details
  -------

  Import control is provided by a set of tags attached to the target point records:
  
  - 'csvColumn': (Required) A string or number specifying the CSV column corresponding to the target
    record:
    - If the CSV file has column headers, 'csvColumn' must be a string that matches a column header.
    - If the CSV file does not have headers (i.e. 'noHeader' option for `ioReadCsv`), then 
      'csvColumn' may be either a string in the form "v#", where # is the column position, or an
      integer that specifies the column position. Note that SkySpark is zero-indexed, i.e. the first 
      column has position 0.
  - 'csvUnit': String specifying the units of numeric CSV data. If 'csvUnit' is missing but SkySpark
    'unit' is present, 'unit' will be used instead.
  - 'csvCallback': Callback function to be applied to the CSV data; follows the same conventions as
    [OnWrite]`ext-his::doc#onWrite` callbacks.
  - 'csvConvert': Point value conversion as described in [Point Conversion]`ext-point::doc#convert`
    to be applied to the CSV data.
  - 'csvRollupInterval': Number that defines a rollup interval for the CSV data.
  - 'csvRollupFunc': String that defines a rollup function for the CSV data.
  
  Each record in **recs** must have the 'csvColumn' tag. The other tags are optional, but provide a
  flexible framework for parsing and modifying the imported CSV data prior to writing history to the
  target points. The key to properly specifying these tags to achieve a desired outcome is
  understanding the order of operations that occur on data import. The import workflow proceeds as
  follows:
  
  1. Raw data is read from **uri**.
  2. The raw data is filtered for each point in **recs**:
     - The 'tsColumn' option gives the time stamp column.
     - The point's 'csvColumn' tag gives the value column.
  3. Time stamps are parsed according to the 'tsPattern' option.
  4. Values are parsed according to the point's 'kind' tag and assigned units according to the
     'csvUnit' tag (if specified).
  5. If the point has a 'csvCallback' tag, the function it specifies is applied to the imported
     data.
  6. If the point has a 'csvConvert' tag, the point conversion it specifies is applied to the
     imported data using the `pointConvert` function.
  7. If the point has a 'csvRollupInterval' tag, the data are rolled up to the specified interval
     using `hisRollup` with the rollup function specified by the 'csvRollupFunc' tag. If the
     'csvRollupFunc' tag is missing, then `hisRollupAuto` is used instead.
  8. Any rows with time stamps that overlap with the point's existing history (i.e. time stamps
     prior to the point's 'hisEnd' tag) are dropped from the data set.
  9. Time stamps are converted to the point's time zone and numeric values are converted to the
     point's SkySpark unit.
  10. The data are written to SkySpark history (which triggers the [OnWrite]`ext-his::doc#onWrite`
      action if the `hisOnWrite` tag is present).
  
  Notes
  -----
  
  1. At present, only numeric and Boolean 'kind''s are supported.
  2. For CSV data without headers, include the 'noHeader' marker tag in **opts** dict.
  3. If the 'tsPattern' option is a list, then the function will try to parse the timestamp using
     each specified pattern in the list in order until either one is successful or they have all
     been exhausted.
  4. Any records which cannot be interpreted correctly as their associated data type are dropped,
     with a warning.
  5. This function is safe to call within a job in order to automatically keep existing point
     histories up to date.
src:
  (recs, uri, opts:{}) => do

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({tsColumn:"ts", tsPattern:"YYYY-MM-DD hh:mm:ss", tz:now().tz, checked:false}, opts)

    // Valid pass-through options for ioReadCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])

    // Convert tsPattern to pattern list
    if ( not(isList(opts->tsPattern)) ) opts = opts.set("tsPattern", [opts->tsPattern])

    // Extract checked option
    checked: opts->checked

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Parse Booleans from Numbers or Text
    ////////////////////////////////////////////////////////////////////////////////////////////////

    // Map CSV column headers
    mapCsvColName: n => if (ioOpts.has("noHeader") and n.isNumber) ("v" + n) else n.toTagName

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Parse Date/Time Using Multiple Patterns
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // 
    myParseDateTime: (x, pattern, tz, checked:checked) => do
      // Try each pattern until one succeeds
      ts: pattern.eachWhile() (pat) => x.parseDateTime(pat, tz, false)

      // If none was successful, throw an exception
      if (ts == null and checked) do
        throw "Unable to parse date/time '" + x + "' using any of the specified patterns: " + pattern
      end

      // Return
      return ts
    end

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Parse Booleans from Numbers or Text
    ////////////////////////////////////////////////////////////////////////////////////////////////
    myParseBool: (x, checked:checked) => do
      // First, try parsing as a Boolean
      y: x.lower.parseBool(false)

      // Next, try parsing as a number
      if (y == null) do
        y = x.parseNumber(false)
        if (y != null) y = y != 0
      end

      // If nothing was successful, throw an exception
      if (y == null and checked) do
        throw "Unable to parse '" + x + "' as boolean."
      end

      // Return
      return y
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Write Point History to Folio
    //////////////////////////////////////////////////////////////////////////////////////////////////
    writePointHis: (point, timeCol, valCol, data) => do
      // Drop all but the two columns we need
      data = data.keepCols([timeCol, valCol])

      // If data column is missing, terminate early
      if (not (data.has(valCol))) return null

      // Rename columns
      data = data.renameCol(timeCol, "ts")
      data = data.renameCol(valCol, "val")

      // Drop rows which have empty timestamp or data
      data = data.findAll() row => row.has("ts") and row.has("val")

      // Parse according to point metadata
      if (point->kind=="Number" and point.has("csvUnit")) do
        // Convert to number w/ appropriate units
        data = data.map row => {
          ts: row->ts.myParseDateTime(opts->tsPattern, opts->tz, checked),
          val: row->val.parseNumber(checked).as(point->csvUnit)
        }

      else if (point->kind=="Number") do
        // Convert to unitless number
        data = data.map row => {
          ts: row->ts.myParseDateTime(opts->tsPattern, opts->tz, checked),
          val: row->val.parseNumber(checked)
        }

      else if (point->kind=="Bool") do
        // Convert to boolean status
        data = data.map row => {
          ts: row->ts.myParseDateTime(opts->tsPattern, opts->tz, checked),
          val: row->val.myParseBool(checked)
        }
        
      else do
        // Unsupported kind
        throw "Kind \"" + point->kind + "\" is not supported."

      end

      // Drop incorrectly parsed rows (with a warning)
      before: size(data)
      data = data.findAll row => row.has("ts") and row.has("val")
      after: size(data)
      if (after < before) do
        logWarn("csvImportHistory", "Unable to parse " + (before - after) + " rows of data for column '" + valCol + "'.")
      end

      // Sort on timestamp
      data = data.sort("ts")

      // Apply callback function
      if (point.has("csvCallback")) do
        // Get callback function
        cb: eval("x:" + func(point->csvCallback)->name)

        // Apply transformation
        data = cb(data, point)
      end

      // Apply value conversion
      if (point.has("csvConvert")) do
        // Apply point conversion
        data = data.hisMap() v => pointConvert(point, point->csvConvert, v)
      end

      // Apply rollup function
      if (point.has("csvRollupInterval")) do
        // Rollup function
        if (point.has("csvRollupFunc")) do
          // User-specified rollup function
          data = data.hisRollup(eval("x:"+point->csvRollupFunc), point->csvRollupInterval)
        else do
          // Automatic rollup function
          data = data
            .addColMeta("val", point)
            .hisRollupAuto(point->csvRollupInterval)
        end

        // Drop rows for which rollup function produced null data
        data = data.findAll row => row.has("ts") and row.has("val")

        // Return if empty (no new data)
        if (data.isEmpty) return null
      end

      // Convert from CSV units to SkySpark units
      if (point->kind=="Number" and point.has("unit")) do
        data = data.map() row => row.set("val", (row->val).to(point->unit))
      end

      // Convert from input timezone to point timezone
      if (point.has("tz")) do
        data = data.map() row => row.set("ts", (row->ts).toTimeZone(point->tz))
      end

      // Write history to point
      data.hisWrite(point)

      // Return processed point id
      return {id:point["id"]}
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Timestamp column name
    tsColumn: opts->tsColumn.mapCsvColName

    // Valid points of interest
    p: recs.toRecList.findAll() x => x.has("csvColumn")

    // Valid CSV headers = timestamp + CSV column names from point metadata
    h: [tsColumn].addAll(p.map() point => mapCsvColName(point->csvColumn))

    // Read the data and subset to needed columns
    try do
      d: ioReadCsv(uri, ioOpts).keepCols(h)
    catch (ex) do
      // If error, log, and rethrow error
      logErr("csvImportHistory", "Error reading URI: " + uri)
      throw (ex)
    end

    // Extract relevant data for each rec and store to Folio
    errorFound: false
    p = p.map() point => do
      // Catch and log any errors
      try do
        point = writePointHis(point, tsColumn, mapCsvColName(point->csvColumn), d)
      end catch (ex) do
        logErr(
          "csvImportHistory", "Error writing history for record " + point->id + "." +
          "Error message was: " + ex->dis
        )
        errorFound = true
        return null
      end
      return point
    end

    // Error check
    if (errorFound) throw "Errors occured while importing CSV history from `" + uri + "`. See Log."

    // Re-read and return list of all affected recs
    p = p.removeNull
    if (p.isEmpty) do
      return null
    else do
      return p.map() rec => readById(rec->id)
    end
  end
---
name:csvImportPoints
func
doc:
  Imports point records from CSV data. Intended for use in tailored CSV import scripts.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of imported point records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'dryrun': Marker; if present then records will be read and returned but not committed to the
    Folio
  - 'flag': string specifying the name of a marker tag to apply to the new records as a flag
  - 'log': Boolean indicating whether log entries should be made for each imported record
  - 'template': A CSV template for supplemental columns; see `csvReadRecs`
  
  If supplied, 'template' will be merged with the default template (see *Details*). In the case of
  conflicts, the user-specified template entries take precedence.
  
  In addition, valid options for `csvReadRecs` may be supplied and will be passed through.
  
  Details
  -------
  
  This function expects a CSV file with some or all of the following columns:

    Tag        | Type    | Description
    ---------- | ------- | ------------------------------------------
    pointName  | string  | Name of point; used to set 'navName'
    pointTags  | taglist | Arbitrary list of tags to apply using Axon
    siteName   | string  | Name of site; used to construct 'siteRef'
               |         | by matching site name
    siteRef    | ref     | Site reference; silently overrides
               |         | 'siteName'
    equipName  | string  | Name of equip; used to construct 'equipRef'
               |         | by matching equip name
    equipRef   | ref     | Equip reference; silently overrides
               |         | 'equipName'
    kind       | string  | Kind of point (e.g. "Number" or "Bool");
               |         | must match SkySpark kind
    unit       | string  | Unit for point data (e.g. "kW")
  
  This default template can be modified using the 'template' option. Other arbitrary column names
  are also supported and will import as strings. See `csvReadRecs` for the low-level import
  function.
  
  Notes
  -----
  
  1. All imported points receive the 'point', 'his', and 'analytics' tags automatically. If an
     import 'flag' option is specified, imported points receive it as a marker tag as well.
  2. The following columns are required:
     - 'pointName'
     - Either 'equipName' or 'equipRef'
     - Either 'siteName' or 'siteRef'
     Other columns are optional.
  3. If the time zone 'tz' is missing, the new point will inherit the parent site's time zone (if
     any) or else the project time zone.
  4. If the function is unable to make a unique match to an existing site using 'siteName' or to an
     existing equip using 'equipName' , it will throw an error.
  5. Parsing failures will throw an error. In the event of a parsing failure, check the CSV data
     for errors.
src:
  (uri, opts:{}) => do

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({log:true}, opts)

    // Tags to add
    addTags: {point, his, analytics}
    if (opts.has("flag")) addTags = addTags.set(opts->flag, marker())

    // CSV Template
    template: {
      pointName:"string",
      pointTags:"taglist",
      siteName:"string",
      siteRef:"ref",
      equipName:"string",
      equipRef:"ref",
      kind:"string",
      unit:"string"
    }
    if (opts.has("template")) template = merge(template, opts->template)

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Add new record
    addRec: (msg, tags) => do

      // Remove null tags
      tags = tags.findAll v => v != null

      // Log an info message
      if (opts->log) logInfo("import", msg)

      // Add as new record to the database
      commit(diff(null, tags, {add}))
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read from CSV
    d: csvReadRecs(uri, template, opts)

    // Process records and commit to database
    d.map() row => do
      // Add universal tags
      row = union(row, addTags)

      // Map site
      if (row.has("siteRef")) do
        siteMatch: readById(row->siteRef, false)
        if (siteMatch == null) throw "Matching site record not found."
        row = row.remove("siteName")

      end else if (row.has("siteName")) do
        siteMatch: readAll(site and dis==row["siteName"])
        if (siteMatch.size != 1) do
          throw "Could not make a unique match for site " + row["siteName"] +
            "; found " + siteMatch.size + " records."
        else do
          row = row.set("siteRef", siteMatch.first->id).remove("siteName")
        end

      end else do
        throw "Either 'siteName' or 'siteRef' is required."
      end
      
      // Map equip
      if (row.has("equipRef")) do
        equipMatch: readById(row->equipRef, false)
        if (equipMatch == null) throw "Matching equip record not found."
        row = row.remove("equipName")

      end else if (row.has("equipName")) do
        equipMatch: readAll(equip and siteRef==row->siteRef and navName==row["equipName"])
        if (equipMatch.size != 1) do
          throw "Could not make a unique match for equip " + row["equipName"] +
            "; found " + equipMatch.size + " records."
        else do
          row = row.set("equipRef", equipMatch.first->id).remove("equipName")
        end

      end else do
        throw "Either 'equipName' or 'equipRef' is required."
      end

      // Set point navName and disMacro
      row = row
        .set("navName", row["pointName"])
        .set("disMacro", "\$equipRef \$navName")
        .remove("pointName")
        
      // Set timezone (if missing)
      if (row.missing("tz")) do
        timezone: readById(row->siteRef)["tz"]
        if (timezone==null) timezone = now().tz
        row = row.set("tz", timezone)
      end

      // Commit
      if (opts.has("dryrun")) do
        return row
      else do
        return addRec("Importing point " + row.dis, row)
      end
    end
  end
---
name:csvImportSites
func
doc:
  Imports site records from CSV data. Intended for use in tailored CSV import scripts.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of imported site records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'dryrun': Marker; if present then records will be read and returned but not committed to the
    Folio
  - 'flag': string specifying the name of a marker tag to apply to the new records as a flag
  - 'log': Boolean indicating whether log entries should be made for each imported record
  - 'template': A CSV template for supplemental columns; see `csvReadRecs`
  
  If supplied, 'template' will be merged with the default template (see *Details*). In the case of
  conflicts, the user-specified template entries take precedence.
  
  In addition, valid options for `csvReadRecs` may be supplied and will be passed through.
  
  Details
  -------
  
  This function expects a CSV file with some or all of the following columns:

    Tag         | Type    | Description
    ----------- | ------- | ------------------------------------------
    siteName    | string  | Name of site; converted to 'dis' tag
    siteTags    | taglist | Arbitrary list of tags to apply using Axon
    area        | number  | Area of site
    geoAddr     | string  | Street address
    geoCity     | string  | City
    geoState    | string  | State / province
    geoCountry  | string  | Country code
    geoCoord    | coord   | Latitude/longitude in decimal format
    tz          | string  | String designation for site time zone
    weatherName | string  | Weather location name; used to construct
                |         | 'weatherRef' by matching weather record
                |         | description
    weatherRef  | ref     | Weather location reference; silently
                |         | overrides 'weatherName'
    
  This default template can be modified using the 'template' option. Other arbitrary column names
  are also supported and will import as strings. See `csvReadRecs` for the low-level import
  function.
  
  Notes
  -----
  
  1. All imported sites receive the 'site' tag automatically. If an import 'flag' option is
     specified, imported sites receive it as a marker tag as well.
  2. All columns except 'siteName' are optional. 
  3. If the time zone 'tz' is missing, the new site will inherit the project's time zone.
     (Determining time zone based on location is not supported at this time.)
  4. If the function is unable to make a unique match to an existing weather location using
     'weatherName', it will throw an error.  
  5. Parsing failures will throw an error. In the event of a parsing failure, check the CSV data
     for errors.
src:
  (uri, opts:{}) => do

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({log:true}, opts)
    
    // Tags to add
    addTags: {site}
    if (opts.has("flag")) addTags = addTags.set(opts->flag, marker())
    
    // CSV Template
    template: {
      siteName:"string",
      siteTags:"taglist",
      area:"number",
      geoAddr:"string",
      geoCity:"string",
      geoState:"string",
      geoCountry:"string",
      geoCoord:"coord",
      weatherName:"string",
      weatherRef:"ref"
    }
    if (opts.has("template")) template = merge(template, opts->template)

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    //////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Add new record
    addRec: (msg, tags) => do

      // Remove null tags
      tags = tags.findAll v => v != null

      // Log an info message
      if (opts->log) logInfo("import", msg)

      // Add as new record to the database
      commit(diff(null, tags, {add}))
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read from CSV
    d: csvReadRecs(uri, template, opts)

    // Process records and commit to database
    d.map() row => do
      // Add universal tags
      row = union(row, addTags)

      // Set site description
      row = row.set("dis", row["siteName"]).remove("siteName")

      // Set timezone (if missing)
      if (row.missing("tz")) row = row.set("tz", now().tz)

      // Map weather location
      if (row.has("weatherRef")) do
        weatherMatch: readById(row->weatherRef, false)
        if (weatherMatch == null) throw "Matching weather location record not found."
        row = row.remove("weatherName")
        
      end else if (row.has("weatherName")) do
        weatherMatch: readAll(weather and dis==row["weatherName"])
        if (weatherMatch.size != 1) do
          throw "Could not make a unique match for weather location " + row["weatherName"] +
            "; found " + weatherMatch.size + " records."
        else do
          row = row.set("weatherRef", weatherMatch.first->id).remove("weatherName")
        end
      end

      // Commit
      if (opts.has("dryrun")) do
        return row
      else do
        return addRec("Importing weather location " + row.dis, row)
      end
    end

  end
---
name:csvImportWeather
func
doc:
  Imports weather location records from CSV data. Intended for use in tailored CSV import scripts.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of imported weather location records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'dryrun': Marker; if present then records will be read and returned but not committed to the
    Folio
  - 'flag': String specifying the name of a marker tag to apply to the new records as a flag
  - 'log': Boolean indicating whether log entries should be made for each imported record
  - 'template': A CSV template for supplemental columns; see `csvReadRecs`
  
  If supplied, 'template' will be merged with the default template (see *Details*). In the case of
  conflicts, the user-specified template entries take precedence.
  
  In addition, valid options for `csvReadRecs` may be supplied and will be passed through.
  
  Details
  -------
  
  This function expects a CSV file with some or all of the following columns:

    Tag         | Type    | Description
    ----------- | ------- | ------------------------------------------
    dis         | string  | Name / label of weather location
    weatherTags | taglist | Arbitrary list of tags to apply using Axon
    geoCity     | string  | City
    geoCoord    | coord   | Geographic coordinates
    geoState    | string  | State / province
    geoCountry  | string  | Country code
    tz          | string  | String designation for location time zone
    
  This default template can be modified using the 'template' option. Other arbitrary column names
  are also supported and will import as strings. See `csvReadRecs` for the low-level import
  function.
  
  Notes
  -----
  
  1. All imported weather locations receive the 'weather' tag automatically. If an import 'flag'
     option is specified, imported weather locations receive it as a marker tag as well.
  2. All columns except 'dis' are optional, although SkySpark may fail to function properly if
     geographic location is not included.
  3. If the time zone 'tz' is missing, the new weather location will inherit the project's time
     zone. (Determining time zone based on location is not supported at this time.)
  4. Parsing failures will throw an error. In the event of a parsing failure, check the CSV data
     for errors.
src:
  (uri, opts:{}) => do

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({log:true}, opts)

    // Tags to add
    addTags: {weather}
    if (opts.has("flag")) addTags = addTags.set(opts->flag, marker())

    // CSV Template
    // Template
    template: {
      dis:"string",
      weatherTags:"taglist",
      geoCity:"string",
      geoCoord:"coord",
      geoState:"string",
      geoCountry:"string"
    }
    if (opts.has("template")) template = merge(template, opts->template)

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Add new record
    addRec: (msg, tags) => do

      // Remove null tags
      tags = tags.findAll v => v != null

      // Log an info message
      if (opts->log) logInfo("import", msg)

      // Add as new record to the database
      commit(diff(null, tags, {add}))
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read from CSV
    d: csvReadRecs(uri, template, opts)
    
    // Process records and commit to database
    d.map() row => do
      // Add universal tags
      row = union(row, addTags)

      // Set timezone (if missing)
      if (row.missing("tz")) row = row.set("tz", now().tz)

      // Commit
      if (opts.has("dryrun")) do
        return row
      else do
        return addRec("Importing weather location " + row.dis, row)
      end
    end
    
  end
---
name:csvImportWeatherPoints
func
doc:
  Imports weather point records from CSV data. Intended for use in tailored CSV import scripts.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of imported weather point records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'dryrun': Marker; if present then records will be read and returned but not committed to the
    Folio
  - 'flag': string specifying the name of a marker tag to apply to the new records as a flag
  - 'log': Boolean indicating whether log entries should be made for each imported record
  - 'template': A CSV template for supplemental columns; see `csvReadRecs`
  
  If supplied, 'template' will be merged with the default template (see *Details*). In the case of
  conflicts, the user-specified template entries take precedence.
  
  In addition, valid options for `csvReadRecs` may be supplied and will be passed through.
  
  Details
  -------
  
  This function expects a CSV file with some or all of the following columns:

    Tag              | Type    | Description
    ---------------- | ------- | ------------------------------------------
    weatherPointName | string  | Name of weatherPoint; converted to 'dis'
    weatherPointTags | taglist | Arbitrary list of tags to apply using Axon
    weatherName      | string  | Weather location name; used to construct
                     |         | 'weatherRef' by matching weather record
                     |         | description
    weatherRef       | ref     | Weather location reference; silently
                     |         | overrides 'weatherName'
    kind             | string  | Kind of weatherPoint (e.g. "Number" or 
                     |         | "Bool"); must match SkySpark kind
    unit             | string  | Unit for weatherPoint data (e.g. "°F")
  
  This default template can be modified using the 'template' option. Other arbitrary column names
  are also supported and will import as strings. See `csvReadRecs` for the low-level import
  function.
  
  Notes
  -----
  
  1. All imported weather points receive the 'point', 'weatherPoint', 'his', and 'analytics' tags
     automatically. If an import 'flag' option is specified, imported points receive it as a marker
     tag as well.
  2. 'weatherPointName' and either 'weatherName' or 'weatherRef' are required; other columns are
     optional.
  3. If the time zone 'tz' is missing, the new weather point will inherit the parent weather
     record's time zone (if any) or else the project time zone.
  4. If the function is unable to make a unique match to an existing weather record using
     'weatherName', it will throw an error.
  5. Parsing failures will throw an error. In the event of a parsing failure, check the CSV data
     for errors.
src:
  (uri, opts:{}) => do

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Setup
    //////////////////////////////////////////////////////////////////////////////////////////////////  

    // Default options
    opts = merge({log:true}, opts)

    // Tags to add
    addTags: {point, weatherPoint, his, analytics}
    if (opts.has("flag")) addTags = addTags.set(opts->flag, marker())

    // CSV Template
    template: {
      weatherPointName:"string",
      weatherPointTags:"taglist",
      weatherName:"string",
      weatherRef:"ref",
      kind:"string",
      unit:"string"
    }  
    if (opts.has("template")) template = merge(template, opts->template)

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Add new record
    addRec: (msg, tags) => do

      // Remove null tags
      tags = tags.findAll v => v != null

      // Log an info message
      if (opts->log) logInfo("import", msg)

      // Add as new record to the database
      commit(diff(null, tags, {add}))
    end

    //////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    //////////////////////////////////////////////////////////////////////////////////////////////////

    // Read from CSV
    d: csvReadRecs(uri, template, opts)

    // Process records and commit to database
    d.map() row => do
      // Add universal tags
      row = union(row, addTags)

      // Map weather location
      if (row.has("weatherRef")) do
        weatherMatch: readById(row->weatherRef, false)
        if (weatherMatch == null) throw "Matching weather location record not found."
        row = row.remove("weatherName")

      end else if (row.has("weatherName")) do
        weatherMatch: readAll(weather and dis==row["weatherName"])
        if (weatherMatch.size != 1) do
          throw "Could not make a unique match for weather location " + row["weatherName"] +
            "; found " + weatherMatch.size + " records."
        else do
          row = row.set("weatherRef", weatherMatch.first->id).remove("weatherName")
        end
        
      end else do
        throw "Either 'weatherName' or 'weatherRef' is required."
      end

      // Set weather point description
      row = row
        .set("dis", row["weatherPointName"])
        .remove("weatherPointName")

      // Set timezone (if missing)
      if (row.missing("tz")) do
        timezone: readById(row->weatherRef)["tz"]
        if (timezone==null) timezone = now().tz
        row = row.set("tz", timezone)
      end

      // Commit
      if (opts.has("dryrun")) do
        return row
      else do
        return addRec("Importing point " + row.dis, row)
      end
    end
  end
---
name:csvReadRecs
func
doc:
  Import records from CSV data using a flexible user-supplied template. This function is *not*
  designed to read and interpret [Haystack-compliant]`https://project-haystack.org/doc/Csv` CSV
  files, but rather to provide a flexible interface for pulling general purpose CSV data into
  Folio records.

  Parameters
  ----------
  
  - **uri:** The URI of the file to read
  - **template:** A dict specifying the data types for the CSV columns; see *Details*
  - **opts:** A dict of control options; see *Options*
  
  Returns
  -------
  
  A grid of dicts ready to commit as Folio records.
  
  Options
  -------
  
  The following options are supported:
  
  - 'delimiter': column delimiter character; passed through to `ioReadCsv`
  - 'noHeader': passed through to `ioReadCsv`
  - 'sep': tag and value separator to use for '"taglist"' and '"coord"' data types; see *Details*
  
  The default value of 'sep' is '" "', which maps to any whitespace character. 'sep' must differ
  from the column 'delimiter' (by default, '","') or parsing will fail.
  
  Details
  -------
  
  Use 'template' to specify how to interpret the CSV columns. In 'template', key names match to
  column names in the CSV file and key values are strings specifying a column data type. Supported
  data types are:
  
  - 'axon': parsed and executed as literal Axon code
  - 'bool': parsed as a boolean
  - 'coord': parsed as a coord; see below
  - 'date': parsed as a date
  - 'datetime': parsed as a dateTime
  - 'marker': any non-empty value is interpreted as setting a marker flag
  - 'number': parsed as a number
  - 'ref': parsed as a reference
  - 'string': parsed as a string
  - 'taglist': parsed as a tag list using Axon; see below
  - 'uri': parsed as a uri
  
  Any other value in the template will throw an error when the corresponding column is parsed, while
  missing columns are parsed as strings by default. Data type values are not case sensitive.
  
  Coordinates ( '"coord"' data type) are processed using the `coord` function. The 'sep' option
  specifies the seperator between the two arguments of 'coord'. Similarly, tag lists ( '"taglist"'
  data type) are processed as dicts using Axon, with 'sep' interpreted as separating the tags in
  the dict. If needed in tag values, 'sep' can be protected by enclosing in quotes or escaped
  with '\'; see `delimConvert` for more information.
  
  Notes
  ------
  
  1. CSV column names should be valid tags, or parsing may fail.
  2. XStr and the Haystack collection data types (Dicts, Lists, and Grids) are not supported
     directly, but can be created indirectly via Axon code by specifying the '"axon"' data type in
     the template. If the Axon expression contains column delimiters, enclose it with quotes.
src:
  (uri, template:{}, opts:{}) => do

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Options
    ////////////////////////////////////////////////////////////////////////////////////////////////  
    
    // Default options
    opts = merge({sep:" "}, opts)
    
    // Valid pass-through options for ioReadCsv()
    ioOpts: opts.findAll() (v, n) => n.in(["delimiter", "noHeader"])
    
    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Functions
    ////////////////////////////////////////////////////////////////////////////////////////////////
    
    // Parsing functions
    parseTags: (s) => delimConvert(s,opts->sep,",").stringToDict
    parseCoord: (c) => eval("coord(" + delimConvert(c,opts->sep,",") + ")")

    ////////////////////////////////////////////////////////////////////////////////////////////////
    // Main
    ////////////////////////////////////////////////////////////////////////////////////////////////

    // Read and parse recs from file
    ioReadCsv(uri, ioOpts).map() row => do
      // Placeholder for output row
      tags: {}

      // Filter null and empty string input
      row = row.findAll() v => (v != null and v != "")
      
      // Handle empty rows
      if (row.isEmpty) return null
      
      // Parse tags
      row.each() (v,n) => do
        // Check for template
        if (template.has(n)) do
          if (template[n].lower == "axon") do
            tags = tags.set(n, eval(v))
          else if (template[n].lower == "bool") do
            tags = tags.set(n, parseBool(v))
          else if (template[n].lower == "coord") do
            tags = tags.set(n, parseCoord(v))
          else if (template[n].lower == "date") do
            tags = tags.set(n, parseDate(v))
          else if (template[n].lower == "datetime") do
            tags = tags.set(n, parseDateTime(v))
          else if (template[n].lower == "marker") do
            tags = tags.set(n, marker())
          else if (template[n].lower == "number") do
            tags = tags.set(n, parseNumber(v))
          else if (template[n].lower == "ref") do
            tags = tags.set(n, parseRef2(v))
          else if (template[n].lower == "string") do
            tags = tags.set(n, v)
          else if (template[n].lower == "taglist") do
            parseTags(v).each((vv,nn) => tags = tags.set(nn,vv))
          else if (template[n].lower == "uri") do
            tags = tags.set(n, parseUri(v))
          else do
            throw "Invalid field type for field " + n + ": " + template[n]
          end

        // No template; use as is
        else do
          tags = tags.set(n,v)
        end
      end

      // Return processed row of tags
      return tags
    end

  end
---
name:delimConvert
func
doc:
  In a string, convert instances of one delimiter to another. Converts instances of delimiter
  character 'old' in string 's' to 'new' (default '","'), under the following rules:
  
  - Delimiters inside quoted strings are ignored
  - Escaped delimiters (instances of 'old' prefixed by '\') are not converted, but the escape
    character '\' is stripped from the output
  - All other instances of 'old' are changed to 'new'
  - Consecutive delimiters are combined
  
  If 'old' is whitespace, then any whitespace character qualifies: space, '\t', '\n', '\r', '\f'.
  
  Examples
  --------

    "a b   c".delimConvert(" ")                     >> a,b,c
    "a;\"b;c\";c".delimConvert(";")                 >> a,"b;c",c
    "name:\"First Last\" age:34".delimConvert(" ")  >> name:"First Last",age:34
    r";\;".delimConvert(";", "|")                   >> |;
  
  Quotes omitted from outputs.
src:
  (s, old, new:",") => do
    // Check delimiter sizes
    if (old.size > 1 or new.size > 1) do
      throw "Old and new delimiters must each be a single character."
    end
    
    // Trivial case
    if (old == new) return s
    
    // Using a whitespace delimiter?
    oldIsSpace: old[0].isSpace
    
    // Setup (output buffer and flags)
    out: ""
    prev: null
    inQuotes: false
    
    // Scan and process input character-by-character
    (0..(s.size-1)).each() i => do
      // Get character
      char: s[i..i]
      
      // Switch...
      
      // Escape character: Buffer one only
      if (char == "\\") do
        if (prev == "\\") do
          out = out + prev
        end
      
      // Escaped quote
      end else if (char == "\"" and prev == "\\") do
        out = out + prev + char
        
      // Unescaped quote
      end else if (char == "\"") do
        inQuotes = not(inQuotes)
        out = out + char
        
      // Inside quotes: As-is
      end else if (inQuotes) do
        out = out + char
        
      // Escaped delimiter
      end else if (char == old and prev == "\\") do
        out = out + char
        
      // Unescaped delimiter
      end else if (char == old) do
        
        // Whitespace delimiter, non-consecutive: Replace
        if (oldIsSpace and not(prev[0].isSpace)) do
          out = out + new
        
        // Non-whitespace delimiter, non-consecutive: Replace
        else if (old != prev) do
          out = out + new
        
        // Consecutive delimiters: Skip (no action)
        end
        
      // All other characters
      end else do
        out = out + char
        
      end
      
      // Update
      prev = char
    end
    
    // Handle edge case: s ends in \
    if (s.endsWith("\\")) out = out + "\\"
    
    // Return
    return out
  end